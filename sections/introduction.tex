\section{Introduction}
\label{sec:intro}

Operating system schedulers face a fundamental challenge: kernel policies cannot understand what applications need. This semantic gap leads to suboptimal performance across modern computing infrastructure. In cloud platforms, system administrators who manage schedulers are not the developers who understand application behavior. On personal devices, regular users lack the expertise to optimize their systems for gaming or creative workloads. Meanwhile, workloads themselves exhibit increasingly dynamic patterns that defy manual optimization.

Prior attempts to automate scheduler optimization, such as those using reinforcement learning~\cite{mao2019decima, qiu2020firm}, have shown promise but remain fundamentally limited. By mapping numerical state to predefined actions, they cannot grasp the semantic intent of a workload and miss optimization opportunities that require deeper reasoning. The advent of Large Language Models (LLMs) Agents, which can automatically reason and use tools for software development, presents an opportunity to bridge this semantic gap, yet a naive approach is impractical. As our motivating experiments reveal, using a powerful agent to generate a basic scheduler from scratch was slow, expensive (\textasciitilde\$6), and resulted in code that often degraded system performance. This highlights a critical gap: existing methods lack semantic understanding, while powerful new models lack the necessary scaffolding for safe, efficient, and reliable systems integration.

To bridge this gap, we introduce a novel, decoupled architecture consisting of two complementary components that leverages AI's unique strengths (semantic reasoning and generative synthesis) while mitigating its weaknesses of cost and unreliability. The first component is \sys, a control plane framework that acts as a safe, stable interface between AI and the kernel \sys\ provides the essential tools for observation, validation, and deployment that any AI agent needs to optimize schedulers. The second component is \agent, our implementation of an autonomous policy engine that leverages a multi-agent LLM system. \agent\ uses the capabilities provided by \sys\ to reason about workloads, synthesize policies, and learn from outcomes.

This architectural separation is fundamental to our approach. \sys\ embodies our core systems contribution: a generalizable framework that can work with any future AI agent, while \agent\ demonstrates the power of this approach through semantic workload analysis and intelligent policy generation. The name `\sys` is inspired by "Context Protocol" (like MCP) and the networking concept of a "Control Plane," reflecting its role as a control plane for AI-driven policy orchestration, separate from the data plane where low-level scheduling decisions execute. Deployed on the production-ready sched\_ext infrastructure, our approach executes with zero LLM overhead in the critical path and makes the following contributions:

\begin{itemize}
    \item \textbf{The \sys\ interface}: A framework that exposes kernel scheduling related features via the Model Context Protocol (MCP), featuring three core services (Workload Analysis Engine, Scheduler Policy Repository, and Execution Verifier) that enable any agent to perform deep semantic analysis of workloads, do AI-driven scheduler optimization without compromising system stability, and learns from experience and improve performance over time.
    \item \textbf{\agent\ multi-agent system}: An autonomous policy engine built on Claude Code's subagent architecture that decomposes scheduler optimization into four specialized agents (Observation, Planning, Execution, and Learning), demonstrating how LLMs can bridge the semantic gap between application requirements and kernel scheduling policies.
    \item \textbf{Evaluation}: We demonstrate that \agent\ achieves up to 1.79× performance improvement on kernel compilation, 50\% latency reduction on scheduler benchmarks, and 88\% cost reduction compared to naive approaches, while maintaining system stability across diverse workloads.
\end{itemize}

Paper organization: Background (§\ref{sec:background}), Motivation (§\ref{sec:motivation}), \sys (§\ref{sec:schedcp_framework}), \agent (§\ref{sec:sched_agents}), Evaluation (§\ref{sec:evaluation}), Related Work (§\ref{sec:related}), Future Work (§\ref{sec:future}), and Conclusion (§\ref{sec:conclusion}).
