\section{Introduction}
\label{sec:intro}

Operating system schedulers face a fundamental challenge: kernel policies cannot understand what applications need. This semantic gap leads to suboptimal performance across modern computing infrastructure. In cloud platforms, system administrators who manage schedulers are not the developers who understand application behavior. On personal devices, users lack the kernel expertise to optimize their systems for gaming or creative workloads. Meanwhile, workloads themselves are increasingly dynamic—a machine learning training job may shift from compute-intensive to I/O-bound phases, requiring different scheduling strategies that no human can adjust in real-time.

Prior attempts to automate scheduler optimization, such as those using reinforcement learning~\cite{mao2019decima, qiu2020firm}, have shown promise but remain fundamentally limited. By mapping numerical state to predefined actions, they cannot grasp the semantic intent of a workload and miss optimization opportunities that require deeper reasoning. The advent of Large Language Models (LLMs) presents an opportunity to bridge this semantic gap, yet a naive approach is impractical. As our motivating experiments reveal, using a powerful agent to generate a basic scheduler from scratch was slow, expensive (\textasciitilde\$6), and resulted in code that often degraded system performance. This highlights a critical gap: existing methods lack semantic understanding, while powerful new models lack the necessary scaffolding for safe, efficient, and reliable systems integration.

This paper introduces \sys, a framework that successfully bridges this gap by structuring an LLM agent as an autonomous policy engine within a safe control plane. Our core insight is that the challenge is not merely to \emph{apply} an LLM, but to architect an interface that leverages its unique strengths—semantic reasoning and generative synthesis—while mitigating its weaknesses of cost and unreliability. \sys achieves this through a principled design: it enables the agent to perform deep semantic analysis of workloads to select or generate tailored eBPF scheduling policies, enforces safety through a rigorous ``Execution Gauntlet'' that validates all agent-generated code before deployment, and maintains a self-evolving library of schedulers that learns from experience to dramatically reduce cost and improve performance over time.

Deployed on the production-ready sched\_ext infrastructure, our approach executes with zero LLM overhead in the critical path. We make the following contributions:
\begin{itemize}
    \item The design and implementation of \sys, a novel framework that leverages an LLM agent as an autonomous control plane to optimize OS schedulers.
    \item A set of generalizable design principles for safely and efficiently integrating AI agents with critical systems software, addressing key challenges of decoupling, safety, and context management.
    \item A comprehensive evaluation demonstrating that our AI-driven approach is highly effective in practice, achieving up to 80\% performance improvements on real-world workloads like kernel compilation.
\end{itemize}

Paper organization: Background (§\ref{sec:background}), Motivation (§\ref{sec:motivation}), Design (§\ref{sec:design}), Implementation (§\ref{sec:implementation}), Evaluation (§\ref{sec:evaluation}), Related Work (§\ref{sec:related}), Future Work (§\ref{sec:future}), and Conclusion (§\ref{sec:conclusion}).