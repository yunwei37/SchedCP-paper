\section{Introduction}
\label{sec:intro}

Operating system schedulers face a fundamental challenge: kernel policies cannot understand what applications need. This semantic gap leads to suboptimal performance across modern computing infrastructure. In cloud platforms, system administrators who manage schedulers are not the developers who understand application behavior. On personal devices, regular users lack the expertise to optimize their systems for gaming or creative workloads. Meanwhile, workloads themselves exhibit increasingly dynamic patterns that defy manual optimization.

Prior attempts to automate scheduler optimization, such as those using reinforcement learning~\cite{mao2019decima, qiu2020firm}, have shown promise but remain fundamentally limited. By mapping numerical state to predefined actions, they cannot grasp the semantic intent of a workload and miss optimization opportunities that require deeper reasoning. The advent of Large Language Models (LLMs) presents an opportunity to bridge this semantic gap, yet a naive approach is impractical. As our motivating experiments reveal, using a powerful agent to generate a basic scheduler from scratch was slow, expensive (\textasciitilde\$6), and resulted in code that often degraded system performance. This highlights a critical gap: existing methods lack semantic understanding, while powerful new models lack the necessary scaffolding for safe, efficient, and reliable systems integration.

To bridge this gap, we introduce a novel, decoupled architecture consisting of two complementary components. The first component is \sys, a control plane framework that acts as a safe, stable interface between AI and the kernel. \sys\ provides the essential tools for observation, validation, and deployment that any AI agent needs to optimize schedulers. The second component is \agent, our implementation of an autonomous policy engine that leverages a multi-agent LLM system. \agent\ uses the capabilities provided by \sys\ to reason about workloads, synthesize policies, and learn from outcomes.

This architectural separation is fundamental to our approach. \sys\ embodies our core systems contribution: a generalizable framework that can work with any future AI agent, while \agent\ demonstrates the power of this approach through semantic workload analysis and intelligent policy generation. The name `\sys` is inspired by "Context Protocol" (like MCP) and the networking concept of a "Control Plane," reflecting its role as a control plane for AI-driven policy orchestration, separate from the data plane where low-level scheduling decisions execute.

Our core insight is that the challenge is not merely to \emph{apply} an LLM, but to architect a durable interface that leverages AI's unique strengths (semantic reasoning and generative synthesis) while mitigating its weaknesses of cost and unreliability. Deployed on the production-ready sched\_ext infrastructure, our approach executes with zero LLM overhead in the critical path and makes the following contributions:

\begin{itemize}
    \item \textbf{The \sys\ interface}: A framework that exposes kernel scheduling related features via the Model Context Protocol (MCP), featuring three core services (Workload Analysis Engine, Scheduler Policy Repository, and Execution Verifier) that enable any agent to perform deep semantic analysis of workloads, do AI-driven scheduler optimization without compromising system stability, and learns from experience and improve performance over time.
    \item \textbf{The \agent\ multi-agent system}: An autonomous policy engine built on Claude Code's subagent architecture that decomposes scheduler optimization into four specialized agents (Observation, Planning, Execution, and Learning), demonstrating how LLMs can bridge the semantic gap between application requirements and kernel scheduling policies.
    \item \textbf{experimental evaluation}: We demonstrate that \agent\ achieves up to 80\% performance improvement on kernel compilation, 50\% latency reduction on scheduler benchmarks, and 88\% cost reduction compared to naive approaches, while maintaining 95\% success rate and system stability across diverse workloads.
\end{itemize}

Paper organization: Background (§\ref{sec:background}), Motivation (§\ref{sec:motivation}),  \sys (§\ref{sec:schedcp_framework}), \agent (§\ref{sec:sched_agents}), Related Work (§\ref{sec:related}), Future Work (§\ref{sec:future}), and Conclusion (§\ref{sec:conclusion}).

% This paper presents \sys, the first framework for using fully automatic LLM agents to dynamically optimize Linux schedulers. The name \sys draws inspiration from both ``Context Protocol'' (similar to MCP server protocols) and the networking concept of ``Control Plane''—emphasizing that our framework operates at the orchestration layer where AI agents manage scheduling policies, rather than in the data plane where actual scheduling decisions execute. Our framework can be leveraged by any AI agent, from open-source Gemini CLI to proprietary agents like Claude Code. A key insight is that LLM agents operate on the control plane, not the data plane—while scheduling decisions occur at microsecond timescales in the kernel, workload patterns change at minute-to-hour timescales, well-suited for LLM optimization. \sys enables AI agents to select, configure, modify, or generate entirely new scheduling algorithms tailored to specific workloads. Built on the production-ready sched\_ext infrastructure, our framework maintains a self-evolving library of schedulers that grows and improves through experience.

% To achieve this vision while addressing the challenges revealed in our experiments, our design is guided by four key principles derived from treating AI agents as context engineering systems and similar to human experts: (1) \textbf{Decoupling} the ``what to optimize'' (AI's domain) from ``how to observe and act'' (system's domain); (2) \textbf{Context Balance} to provide sufficient information for decisions while controlling costs, and give feedback earlier; (3) \textbf{Composable Tools} that leverage LLM Agent's dynamic planning, code generation and tool usage capabilities; and (4) \textbf{Safety-First Design} that treats AI as potentially non-cautious actors requiring defensive interfaces. These principles ensure our system remains effective as AI models evolve while preventing catastrophic failures. We think these principles also are generalizable to other domains and systems.

% Following these principles, we implement \sys with five core components: (1) static analysis and testing for safe code deployment, (2) scheduler libraries with reusable optimization patterns, (3) reinforcement learning for continuous improvement, (4) profiling tools for workload characterization, and (5) a unified interface enabling any LLM to optimize schedulers. This modular design evolves with AI capabilities without system redesign. Once generated, schedulers execute as native eBPF code with no LLM overhead in the critical path, achieving up to 80\% speedup for Linux kernel builds and 50\% latency reduction for scheduler benchmarks.

% We make the following contributions:
