\section{Background}
\label{sec:background}

\subsection{Linux Scheduling and sched\_ext}

Linux's default CFS (Completely Fair Scheduler)~\cite{wong2008cfs} implements a one-size-fits-all policy but is unoptimized for diverse workloads ranging from latency-sensitive web services to throughput-oriented batch jobs. While CFS ensures fairness through virtual runtime, modern systems require adaptive scheduling. sched\_ext~\cite{schedext2024}, introduced in Linux 6.12, enables dynamic loading of custom schedulers as eBPF programs without kernel modifications. Built on eBPF~\cite{mccanne1993bpf,gregg2019bpf}, which evolved from packet filtering into a general-purpose in-kernel VM, sched\_ext provides hooks for task enqueueing, CPU selection, load balancing, and idle management. The eBPF verifier ensures safety through static analysis, preventing crashes, invalid memory access, and infinite loops.

\subsection{LLMs and Autonomous Agents}

Large language models (LLMs) like OpenAI’s Codex~\cite{chen2021codex}, GPT-4~\cite{openai2023gpt4}, and Anthropic’s Claude~\cite{anthropic2024claude} have transformed software development, with tools such as GitHub Copilot accelerating coding tasks by over 50\%~\cite{peng2023impact}. The application of LLMs is expanding from developer aids to system maintenance~\cite{de2025llm} and fully autonomous agents. By 2024-2025, systems like GitHub's Copilot Workspace~\cite{dohmke2024copilotworkspace} and Cognition's Devin~\cite{sharma2024devin}, along with multi-agent frameworks such as ChatDev~\cite{qian2024chatdev} and MetaGPT~\cite{hong2023metagpt}, aim to automate the entire software engineering workflow with minimal human intervention. However, these tools still primarily serve as developer aids rather than autonomously optimizing low-level system components. This gap suggests an opportunity to leverage LLM semantic understanding to bridge high-level application needs with underlying system-level optimizations.