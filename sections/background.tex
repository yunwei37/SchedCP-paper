\section{Background}

\subsection{Linux Scheduling and sched\_ext}

Linux's default scheduler, CFS (Completely Fair Scheduler)~\cite{wong2008cfs}, implements a one-size-fits-all policy that cannot adapt to diverse workload requirements. While CFS aims for "ideal, precise multi-tasking" using virtual runtime to ensure fairness, this inflexibility becomes problematic as modern systems host workloads ranging from latency-sensitive web services to throughput-oriented batch jobs. The sched\_ext framework~\cite{schedext2024}, introduced in Linux 6.12, fundamentally changes scheduler development by enabling dynamic loading of custom schedulers as eBPF programs without kernel modifications or reboots. Built on eBPF technology~\cite{mccanne1993bpf,gregg2019bpf}, which evolved from packet filtering into a general-purpose in-kernel VM, sched\_ext provides comprehensive hooks for controlling task enqueueing, CPU selection, load balancing, and idle management. The eBPF verifier performs exhaustive static analysis ensuring programs cannot crash kernels, access invalid memory, or enter infinite loops, making dynamic scheduler generation safe for production. Production schedulers like scx\_rusty (work-stealing), scx\_layered (hierarchical with cgroup awareness), and scx\_central (centralized for NUMA) demonstrate eBPF can implement complex scheduling algorithms matching or exceeding traditional kernel schedulers with minimal overhead (<1\%).

\subsection{LLMs and Autonomous Agents}

Large language models have revolutionized code synthesis with systems like Codex~\cite{chen2021codex} (powering GitHub Copilot), GPT-4~\cite{openai2023gpt4}, and Claude~\cite{anthropic2024claude} generating complex systems code from natural language descriptions. Studies show developers using Copilot complete tasks 55\% faster, particularly for boilerplate and common patterns. The years 2024-2025 mark an inflection point with autonomous agents like Claude Code, GitHub Copilot Workspace, and Devin that exceed code completion to perform complete software engineering workflowsâ€”understanding requirements, architecting solutions, implementing across files, writing tests, debugging failures, and iterating based on results. AIOS~\cite{mei2024aios} proposes fundamental OS changes supporting AI agents as first-class citizens with LLM-aware process scheduling and semantic memory spaces. However, a critical gap remains: these tools assist human developers rather than autonomously optimize system components. This presents an opportunity to leverage LLMs' semantic understanding of both high-level requirements and low-level implementation details to bridge the gap between application needs and kernel scheduler capabilities.

\subsection{ML for Systems Context}

Machine learning has transformed fundamental system components, demonstrating AI's potential to improve even well-studied algorithms. Learned indexes~\cite{kraska2018learned} replace B-trees with neural networks, achieving up to 70\% memory savings and 3x lookup performance improvements by recognizing that indexes are essentially models mapping keys to positions. In scheduling, Decima~\cite{mao2019decima} uses graph neural networks for datacenter job scheduling, reducing completion time by 40\%, while Firm~\cite{qiu2020firm} addresses multi-resource cluster scheduling with fairness constraints, improving utilization by 25-30\%. Park~\cite{mao2019park} provides a general platform for applying RL to systems problems. Neo~\cite{marcus2019neo} applies deep RL to database query optimization, achieving 2x performance improvements, while OtterTune~\cite{vanaken2017ottertune} uses Gaussian Process regression to tune database configurations, reaching 94\% of expert DBA performance. However, these approaches share fundamental limitations: they require extensive training (millions of decisions), cannot transfer knowledge between workloads, and operate on statistical patterns without semantic understanding. Our work differs by combining LLMs' semantic understanding with systems optimization, enabling immediate application of domain knowledge without extensive training.