\section{Background}
\label{sec:background}

\subsection{Linux Scheduling and sched\_ext}

Linux's default scheduler, CFS (Completely Fair Scheduler)~\cite{wong2008cfs}, implements a one-size-fits-all policy that cannot adapt to diverse workload requirements. While CFS aims for "ideal, precise multi-tasking" using virtual runtime to ensure fairness, this inflexibility becomes problematic as modern systems host workloads ranging from latency-sensitive web services to throughput-oriented batch jobs. The sched\_ext framework~\cite{schedext2024}, introduced in Linux 6.12, fundamentally changes scheduler development by enabling dynamic loading of custom schedulers as eBPF programs without kernel modifications or reboots. Built on eBPF technology~\cite{mccanne1993bpf,gregg2019bpf}, which evolved from packet filtering into a general-purpose in-kernel VM, sched\_ext provides comprehensive hooks for controlling task enqueueing, CPU selection, load balancing, and idle management. The eBPF verifier performs exhaustive static analysis ensuring programs cannot crash kernels, access invalid memory, or enter infinite loops, making dynamic scheduler generation safe for production. Production schedulers like scx\_rusty (work-stealing), scx\_layered (hierarchical with cgroup awareness), and scx\_central (centralized for NUMA) demonstrate eBPF can implement complex scheduling algorithms matching or exceeding traditional kernel schedulers with minimal overhead (<1\%).

\subsection{LLMs and Autonomous Agents}

Large language models have revolutionized code synthesis with systems like Codex~\cite{chen2021codex} (powering GitHub Copilot), GPT-4~\cite{openai2023gpt4}, and Claude~\cite{anthropic2024claude} generating complex systems code from natural language descriptions. Studies show developers using Copilot complete tasks 55\% faster, particularly for boilerplate and common patterns. The years 2024-2025 mark an inflection point with autonomous agents like Claude Code, GitHub Copilot Workspace, and Devin that exceed code completion to perform complete software engineering workflowsâ€”understanding requirements, architecting solutions, implementing across files, writing tests, debugging failures, and iterating based on results. AIOS~\cite{mei2024aios} proposes fundamental OS changes supporting AI agents as first-class citizens with LLM-aware process scheduling and semantic memory spaces. However, a critical gap remains: these tools assist human developers rather than autonomously optimize system components. This presents an opportunity to leverage LLMs' semantic understanding of both high-level requirements and low-level implementation details to bridge the gap between application needs and kernel scheduler capabilities.

