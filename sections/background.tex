\section{Background}

\subsection{Evolution of Linux Schedulers}

\subsubsection{Traditional Linux Schedulers}

Linux's scheduling subsystem evolved significantly over decades. CFS (Completely Fair Scheduler), introduced in Linux 2.6.23, is the current default and aims for "ideal, precise multi-tasking" for all runnable tasks~\cite{wong2008cfs}. CFS models an ideal processor running multiple tasks simultaneously with equal processor time shares. On real hardware, CFS uses a red-black tree of runnable tasks sorted by "virtual runtime," scheduling tasks with least CPU time first.

Linux also provides real-time scheduling classes (SCHED\_FIFO and SCHED\_RR) offering deterministic behavior for time-critical apps. These use fixed priorities and preempt normal tasks, suiting embedded and real-time systems. But all traditional schedulers share a key limitation: they implement one-size-fits-all policies that can't adapt to specific app requirements or workload characteristics. This inflexibility is increasingly problematic as modern systems host diverse workloads from latency-sensitive web services to throughput-oriented batch jobs.

\subsubsection{sched\_ext (Scheduler Extensions)}

sched\_ext in Linux 6.12 marks a paradigm shift in kernel scheduler development~\cite{schedext2024}. This framework lets developers implement custom schedulers as BPF programs dynamically loaded into the kernel without modifications or reboots. For the first time in Linux history, scheduler development can proceed at user-space speed while maintaining kernel-level performance and safety.

sched\_ext provides comprehensive callbacks for BPF schedulers to control all scheduling aspects: task enqueueing, CPU selection, load balancing, and idle CPU management. The framework ensures production readiness with minimal overhead (typically <1\% in real workloads) while providing safety through BPF verification. This flexibility, safety, and performance combination makes sched\_ext ideal for experimenting with novel scheduling algorithms, including AI-generated ones.

\subsubsection{eBPF Technology}

eBPF evolved from packet filtering into a general-purpose in-kernel VM enabling safe execution of user programs in kernel space~\cite{mccanne1993bpf,gregg2019bpf}. The eBPF verifier does extensive static analysis ensuring programs can't crash the kernel, access invalid memory, or enter infinite loops. Verification examines all execution paths and enforces strict bounds on loops and memory access.

JIT compilation of eBPF bytecode to native instructions ensures near-native performance, making eBPF suitable for performance-critical paths like scheduling. eBPF already transformed networking, tracing, and security subsystems. Its application to scheduling via sched\_ext brings programmability and safety benefits to schedulers. The rich eBPF ecosystem (bpftool, libbpf, tracing utilities) provides a mature foundation for developing and debugging schedulers.

\subsubsection{Infrastructure Challenges}

Modern infrastructure faces unprecedented scheduling challenges beyond traditional approaches. In clouds, the gap between admins configuring schedulers and developers understanding workload requirements creates a knowledge gap. Admins must optimize diverse workloads without deep app understanding, while developers lack kernel expertise to influence scheduling.

Workload heterogeneity complicates scheduling further. One machine might run latency-critical web services needing microsecond responses, throughput-optimized batch jobs, and ML workloads alternating between compute and communication phases. Static policies can't adapt to these dynamic needs, causing poor performance and utilization. Studies show many HPC centers achieve <50\% utilization from conservative scheduling~\cite{feitelson2023utilization}, with clouds reporting similar inefficiencies.

\subsubsection{Emerging Workload Types}

Computing evolved dramatically with new workload paradigms. ML/AI workloads present unique challenges with alternating compute-intensive training and memory-bound inference phases. They show bursty behavior needing careful CPU-accelerator scheduling coordination. Serverless/FaaS platforms introduce extreme dynamism with millisecond-to-second function execution requiring rapid cold-start optimization.

Microservices decompose apps into hundreds of interconnected services with distinct performance needs and complex communication patterns, creating challenges for tail latency and resource isolation. Batch systems evolved to handle jobs from seconds to days with varying resources and deadlines. Traditional schedulers struggle with this diversity, often using conservative allocation that wastes performance.

\subsubsection{Performance Requirements}

Different app classes need different scheduling. Latency-sensitive apps (web services, databases) need predictable, low-latency scheduling, often <100 microseconds response times. They benefit from dedicated CPUs and minimal context switching. Throughput-oriented workloads (batch processing, analytics) tolerate higher latencies but need efficient utilization and fair sharing across jobs.

Resource-efficient scheduling is critical in edge/IoT environments dominated by power and thermal constraints. These need schedulers dynamically adjusting performance based on resources and conditions. App-specific workloads like build systems offer unique optimizations—e.g., prioritizing compilation by dependency graphs significantly reduces build times. This diversity requires adaptive scheduling tailored to specific workload characteristics.

\subsection{AI/ML in Systems Optimization}

\subsubsection{Reinforcement Learning for OS}

RL for OS optimization gained momentum with several successes showing learned policies' potential. Decima~\cite{mao2019decima} (SIGCOMM 2019) pioneered graph neural networks for datacenter job scheduling, optimizing completion times by considering task dependencies. It improved average job completion time up to 40\% over traditional heuristics.

Firm~\cite{qiu2020firm} (OSDI 2020) extended RL to multi-resource cluster management with fairness constraints. Modeling clusters as multi-agent systems, Firm learns policies balancing efficiency and fairness. Park~\cite{mao2019park} provides a platform for applying RL to various systems problems, showing the approach's generality.

But RL systems face key limitations motivating our work. First, they need extensive training per workload/environment, often millions of decisions to converge. Second, they can't leverage domain knowledge or understand app semantics—they work purely on statistical patterns. Third, learned policies are black boxes with no decision explanations, hindering debugging and trust. Most critically, they miss optimizations needing semantic understanding, like prioritizing compilation tasks by dependency analysis.

\subsubsection{LLMs for Code Generation}

LLMs revolutionized code synthesis. Systems like Codex~\cite{chen2021codex} (GitHub Copilot), GPT-4~\cite{openai2023gpt4}, and Claude~\cite{anthropic2024claude} generate complex systems code from natural language. Trained on vast corpora of documentation, code, and technical discussions, they deeply understand programming patterns and system design.

Recent evaluations show LLMs successfully generate various systems code, from device drivers to network protocols. Their context understanding and learned patterns suit tasks needing domain knowledge, like implementing scheduling policies for specific workloads. Unlike traditional synthesis needing formal specs, LLMs work from informal descriptions and examples, making them accessible to non-experts.

Key LLM capabilities for scheduler generation: understanding natural language performance requirements, generating correct systems code, reasoning about performance trade-offs and optimizations, learning from documentation and code examples. These capabilities address RL's limitations, suggesting LLM-RL combination could yield superior results.

\subsubsection{AI Agents and Autonomous Systems}

2024 marked an inflection point with fully autonomous coding agents that understand requirements, generate code, test implementations, and iterate on feedback. Claude Code exemplifies this generation, autonomously developing complex software with minimal human intervention. These agents go beyond code completion to genuine software engineering: design, implementation, debugging, and optimization.

GitHub Copilot Workspace extends to repository-wide changes, letting AI understand entire codebases and make coordinated multi-file modifications. Devin shows end-to-end software engineering from requirements through deployment. These systems combine natural language understanding, code generation, test synthesis, and error correction into cohesive agents tackling complex programming tasks.

Evolution from code completion to autonomous agents opens unprecedented system optimization opportunities. Unlike tools assisting humans, these agents work continuously optimizing systems, explore design spaces humans might miss, and accumulate knowledge across optimization tasks. Understanding both high-level requirements and low-level implementation makes them ideal for bridging the semantic gap in scheduler optimization plaguing traditional approaches.

\subsection{RL-based Scheduler Optimization}

Reinforcement learning for scheduling shows promise in systems research, with landmark papers demonstrating learned policies outperforming traditional heuristics. However, these approaches have limitations that motivate our LLM-based approach.

\textbf{Decima}~\cite{mao2019decima}, presented at SIGCOMM 2019, uses graph neural networks to learn job scheduling policies for datacenter environments, reasoning about dependencies between tasks in distributed computing jobs. By representing jobs as directed acyclic graphs with a neural architecture processing variable-sized inputs, Decima reduces average job completion time by up to 40\% compared to traditional heuristics. However, Decima requires extensive training for each workload type, needing millions of scheduling decisions before converging. It operates on statistical patterns in job structures without understanding what jobs do or why certain scheduling decisions benefit. This limitation appears when workloads exhibit rare but important patterns absent from training data.

\textbf{Firm}~\cite{qiu2020firm}, published at OSDI 2020, addresses multi-resource cluster scheduling with fairness constraints. The system models resource allocation as multi-agent reinforcement learning, where each job acts as an agent competing for resources. Firm learns policies balancing efficiency with fairness, preventing job starvation while avoiding resource monopolization. The system improves cluster utilization by 25-30\% while maintaining fairness guarantees in production. However, like Decima, Firm cannot reason about application semantics or understand why workloads benefit from specific strategies. The learned policies remain black boxes without explanations, making debugging and trust difficult in production.

\textbf{Recent advances} in RL-based scheduling include multi-objective RL schedulers like MrSch~\cite{zhang2024mrsch} that optimize CPU, memory, and network bandwidth simultaneously, achieving up to 48\% performance improvements in heterogeneous clusters. These systems use attention mechanisms and transformer models to capture interactions between resource types. Other work explores hierarchical RL for multi-level scheduling and meta-learning for quick adaptation to new workloads. While demonstrating RL's potential, these advances highlight the inability to leverage domain knowledge or understand application intent.

\textbf{Key distinction}: Our approach differs from pure RL methods through semantic understanding. RL-based schedulers learn from scratch through trial and error, while our LLM-based system applies knowledge from training on code and documentation. For compilation workloads, RL systems see only task durations and dependencies, while our system recognizes build processes and applies known optimizations like critical path prioritization. We combine LLMs for initial understanding and generation with RL for workload-specific optimization.

\subsection{AI for Systems}

AI application to systems problems evolved from parameter tuning to reimagining core components. This progression contextualizes our work as the next step in this evolution.

\textbf{Learned Indexes} by Kraska et al.~\cite{kraska2018learned} (SIGMOD 2018) show that database indexes are models mapping keys to positions, and neural networks can learn these mappings more efficiently than B-trees for certain distributions. Replacing B-trees with neural networks achieves up to 70\% memory savings and 3x lookup performance improvements. This sparked rethinking system components through machine learning. Subsequent research extended learned indexes to handle updates, developed hybrid approaches, and applied similar ideas to bloom filters and hash tables. Learned indexes demonstrate AI can improve fundamental system components.

\textbf{Query Optimization} shows AI promise. Neo~\cite{marcus2019neo} (VLDB 2019) uses deep reinforcement learning to optimize database query execution plans. Traditional optimizers rely on inaccurate cost models, leading to suboptimal plans. Neo learns from actual execution times to build accurate cost models and make better decisions, achieving up to 2x performance improvements on analytical queries. Recent work explores transformer models for query structure understanding and multi-armed bandits for adaptive execution strategy selection. These successes demonstrate AI improving complex decisions where traditional heuristics fail.

\textbf{Configuration Tuning} provides immediate AI value. OtterTune~\cite{vanaken2017ottertune} (CMU) uses Gaussian Process regression and collaborative filtering to tune database configuration parameters. Modern databases have hundreds of configuration knobs that challenge even expert DBAs. OtterTune learns from previous tuning sessions to recommend configurations, achieving performance within 94\% of expert DBAs with minimal training data. Similar approaches apply to web server configuration, container resource allocation, and distributed system parameters. These tools optimize existing parameters rather than creating new algorithms or implementations.

\textbf{Our contribution} goes beyond these applications. While learned indexes replace data structures and configuration tuners optimize parameters, we use AI to generate entire system components—complete schedulers with algorithms tailored to workloads. This shifts from AI as optimization tool to AI as system designer. Our approach leverages LLMs' semantic understanding rather than statistical learning. OtterTune treats configuration parameters as opaque numbers; our system understands scheduler parameters' semantic meaning and system behavior effects. This enables intelligent and explainable optimizations.

\subsection{LLMs in Systems and Code Generation}

Large language models with code understanding and generation capabilities open opportunities for automated system optimization. These models, trained on code and documentation, possess knowledge from high-level algorithms to low-level implementation details, suited for systems tasks requiring years of human expertise.

\textbf{Code Generation} advanced with systems like Codex~\cite{chen2021codex} (powering GitHub Copilot), GPT-4, and Claude generating complex systems code. GitHub Copilot transforms development with context-aware suggestions matching or exceeding human code quality. Studies show developers complete tasks 55\% faster using Copilot, particularly for boilerplate and common patterns. However, these tools are developer assistants, not autonomous agents. They complete snippets and implement functions but cannot design entire system components independently. They lack feedback loops for optimization—generating code from training patterns without observing runtime behavior. Recent advances generate entire applications from specifications but focus on functional correctness over performance optimization.

\textbf{Systems Understanding} shows LLM competence. Wang et al.~\cite{wang2024llmsys} demonstrate LLMs analyzing complex system behaviors, debugging performance issues, and suggesting optimizations. GPT-4 correctly diagnoses 78\% of distributed system performance problems given logs and metrics. LLMs understand kernel code, explaining Linux kernel functions with accuracy comparable to experienced developers. This extends to performance implications—models predict which code changes improve or degrade performance from patterns in millions of examples. However, existing applications focus on analysis over synthesis. LLMs explain why schedulers are inefficient, but prior to our work, no systems automatically generated improved implementations.

\textbf{Mapper Generation} by Wei et al.~\cite{wei2024mapper} is the closest prior work. Their system uses LLMs to generate mappers optimizing parallel program execution on heterogeneous hardware. By representing mapping as domain-specific language (DSL) generation, LLMs produce code assigning computation to processing units (CPUs, GPUs, accelerators) based on workload characteristics. The system achieves 3.8× average speedups across parallel workloads. LLMs understand both high-level parallel algorithm structure and low-level hardware details, bridging the semantic gap in manual optimization. However, mapper generation operates in a constrained domain. Mappers use well-defined parallel patterns and clear performance models; schedulers handle arbitrary workloads with complex behaviors. Our work extends to kernel schedulers with stricter safety requirements, subtler performance implications, and complex system state interactions.

\subsection{sched\_ext and eBPF Schedulers}

sched\_ext shifts Linux kernel development paradigms, enabling safe, dynamic scheduler implementation for the first time. This framework provides the foundation for our AI-driven approach, offering flexibility for experimentation and safety guarantees for production deployment.

\textbf{The sched\_ext Framework} changes scheduler development and deployment. Traditional Linux scheduler development required modifying kernel source, recompiling, and rebooting—taking hours and risking stability. With sched\_ext, schedulers are BPF programs loaded and unloaded dynamically without restart. The framework provides hooks into scheduling, allowing BPF programs to control task enqueueing, CPU selection, load balancing, and idle CPU management. This enables novel scheduling algorithms impractical with traditional development. Performance overhead is minimal—typically less than 1\% for production workloads. Major technology companies deploy custom schedulers in production for workload optimization.

\textbf{Production Schedulers} for sched\_ext demonstrate sophisticated scheduling policy support. scx\_rusty implements work-stealing with advanced load balancing, outperforming CFS for many parallel workloads. It uses per-CPU queues with periodic work stealing, implementing NUMA-aware policies minimizing cross-socket traffic. scx\_layered provides hierarchical scheduling with cgroup awareness for different application classes. This proves valuable in cloud environments requiring tenant isolation and different performance guarantees. scx\_central implements centralized scheduling for NUMA systems, where single queues improve performance through better global decisions. These schedulers validate eBPF implementing complex algorithms matching or exceeding traditional kernel schedulers.

\textbf{Safety Guarantees} from the eBPF verifier address critical challenges in dynamic scheduler generation. The verifier performs exhaustive static analysis before loading, ensuring programs cannot crash kernels, access invalid memory, or enter infinite loops. Verification checks all memory accesses are bounds-checked, loops have provable termination, and kernel helpers receive valid arguments. The conservative approach may reject some correct programs but guarantees accepted programs are safe. This safety mechanism is crucial for AI-driven approaches—without it, generated scheduler code poses unacceptable stability risks. The verifier enables experimenting with AI-generated code while maintaining production reliability.

\textbf{Our innovation} adds intelligence to sched\_ext's scheduling layer. While sched\_ext provides safe, dynamic scheduler implementation, it requires human experts to design algorithms. We automate this—using AI to understand workload requirements, generate scheduling algorithms, and implement them as eBPF programs. Combining sched\_ext's flexibility and safety with AI's pattern recognition and code generation enables automatic scheduler optimization for specific workloads. We first demonstrate AI agents generating production-quality kernel schedulers, opening possibilities for adaptive system optimization.

\subsection{AI Agents and Autonomous Systems}

The years 2024-2025 mark an inflection point with autonomous agents capable of complex software engineering tasks. These agents leap from previous AI systems, combining capabilities into cohesive systems working independently on technical problems.

\textbf{Claude Code}, with agents like GitHub Copilot Workspace and Devin, demonstrates unprecedented development capabilities. These agents exceed code completion, engaging complete software engineering workflows. Claude Code understands natural language requirements, architects solutions, implements code across files, writes tests, debugs failures, and iterates—without human intervention. In benchmarks, agents complete real-world tasks previously requiring hours of developer time. The innovation integrates multiple capabilities: natural language understanding, code generation, program analysis, and planning algorithms for multi-step tasks. Our experiments with Claude Code revealed potential and limitations for systems programming, informing framework design to maximize strengths while mitigating weaknesses.

\textbf{AIOS}~\cite{mei2024aios} proposes OS changes supporting AI agents as first-class citizens. Their vision includes LLM-aware process scheduling understanding AI workload requirements like large memory footprints and bursty computation. The system provides AI agent abstractions: semantic memory spaces, natural language system calls, and AI-specific resource management. While we use AI agents to optimize traditional OS components, AIOS explores how operating systems evolve for AI workloads. The approaches are synergistic—our AI-optimized schedulers could run in AIOS environments, while AIOS could use our techniques for automatic scheduling optimization. This points to future AI-OS integration at multiple levels.

\textbf{Agent Capabilities} encompass the full software development lifecycle. Modern agents combine specialized models and tools: code generation models from vast repositories, testing frameworks generating test cases, debugging tools tracing execution and identifying bugs, and planning systems breaking complex tasks into steps. Agents handle tasks requiring understanding of system constraints, performance implications, and correctness requirements. They read codebases, identify optimization opportunities, and implement improvements while maintaining compatibility. Their iteration based on feedback is crucial—running tests, observing failures, and modifying approaches. This closed-loop capability is essential for scheduler optimization where performance requires actual execution validation. Leveraging these capabilities automates scheduler development previously requiring expert kernel developers.

\subsection{Positioning Our Work}

Our work is unique in several ways:

\begin{enumerate}
\item \textbf{First to use LLM agents for OS scheduler generation}: While others use ML for scheduling decisions, we generate entire schedulers.

\item \textbf{Semantic Understanding}: Unlike pure RL approaches, our system understands workload intent and requirements.

\item \textbf{Production-Ready}: Built on sched\_ext, our generated schedulers run in production Linux systems.

\item \textbf{Self-Evolving}: Our scheduler library grows through experience, unlike static ML models.

\item \textbf{Safety-First Design}: We address AI-generated kernel code challenges through comprehensive safety mechanisms.
\end{enumerate}

\subsection{Limitations of Existing Approaches}

Existing approaches have fundamental limitations motivating our research. Each category faces constraints preventing adaptive, intelligent system optimization.

\textbf{RL-based methods} face limitations in production. The extensive training requirement—Decima needs millions of scheduling decisions before converging—makes them impractical for changing workloads or new deployments. Training is not transferable; policies for one workload provide little benefit for another, requiring retraining. RL systems rediscover known scheduling principles through trial and error, wasting resources. Neural network policies provide no decision explanations, making debugging impossible. RL methods miss semantic optimization—they cannot recognize compilation workloads and apply build system optimizations. They see only statistical patterns, missing higher-level structure for better scheduling.

\textbf{Traditional auto-tuning} operates within narrow constraints. Systems optimize existing parameters but cannot create new algorithms or implementations. OtterTune finds optimal buffer pool sizes but cannot invent new buffer management algorithms. Manual feature engineering limits optimization to human-identified tunable parameters. Many opportunities exist in unexposed implementation choices. Adaptation is slow, requiring sufficient samples for accurate models without leveraging workload semantics. Auto-tuning operates within human-defined design spaces rather than exploring new possibilities.

\textbf{Static schedulers}, including Linux CFS, use one-size-fits-all approaches problematic for diverse workloads. They cannot adapt to workload-specific requirements without manual intervention, missing optimization opportunities. New workload patterns—microservices, machine learning training—require manual updates taking years to develop and deploy. Innovation pace is limited by developer resources; known optimizations require scarce kernel expertise. Static schedulers make conservative choices working reasonably for all workloads rather than optimizing for specific patterns. This lowest-common-denominator approach leaves performance gains unrealized for specialized workloads.

Our LLM agent-based approach addresses these limitations differently. Combining LLM semantic understanding, code generation, and continuous RL learning creates a system understanding workload intent, generating specialized implementations, and improving through experience. This framework breaks constraints limiting existing approaches, enabling adaptive, intelligent system optimization.