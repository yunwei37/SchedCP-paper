\section{Motivation}
\label{sec:motivation}

\subsection{The Semantic Gap Problem}

\subsubsection{Domain Knowledge Gap in Modern Infrastructure}

Modern infrastructure suffers from a fundamental disconnect: system managers who optimize schedulers are not the developers who develop the application. In cloud platforms and serverless environments, DevOps engineers configuring Kubernetes policies lack insight into whether workloads are latency-sensitive or throughput-oriented, leading to conservative scheduling that achieves less utilization in many datacenters. This gap is even more pronounced for edge and personal devices—gamers seeking optimal performance, creative professionals needing workload-specific optimizations, and IoT operators managing sensor patterns all lack the kernel expertise to optimize their systems. LLM agents can bridge this semantic gap by understanding workload patterns from high-level descriptions and translating them into concrete scheduling policies, democratizing expert-level optimization for all users.

\subsubsection{Technical Complexity of Scheduler Development}

Designing Linux kernel schedulers requires mastering multiple complex domains: kernel programming with concurrency primitives and lock-free data structures, BPF verification with its limited instruction set and memory restrictions, and deep understanding of CPU architectures, cache hierarchies, and NUMA topologies. This steep learning curve means even experienced developers need months to become productive, limiting innovation to a small group of kernel experts. LLM agents with pre-trained domain knowledge can help bridge this expertise gap, enabling rapid scheduler development without years of specialized training.

\subsubsection{Dynamic Workload Adaptation}

Modern workloads exhibit complex phase behavior that changes faster than humans can respond. ML training alternates between compute-intensive forward propagation and communication-heavy gradient synchronization; web applications see traffic varying by orders of magnitude daily; build systems show varying parallelism as dependencies resolve. Manual reconfiguration cannot keep pace—by the time humans detect and adjust for phase changes, workloads have already transitioned. AI agents can continuously monitor and adapt scheduling policies in real-time, potentially predicting phase transitions from historical patterns.

\subsection{Motivation Experiment: Challenges in applying LLM Agents to scheduler}

To understand the practical challenges, we tested Claude Code with a simple prompt: "write a scheduler in eBPF". While the AI successfully created a working FIFO scheduler without human intervention, the process revealed significant obstacles. Generation required 33 minutes, 221 API calls, and 15+ trial-and-error iterations, costing approximately \$6—compared to an experienced eBPF developer typically completing the same task in 5 minutes. The generated code often exhibited poor quality and cause too much scheduling overhead, that actually worse than CFS. Safety concerns were paramount: the agent required root access, could crash the system during testing, and lacked gradual rollout mechanisms. These results highlight three approaches: human experts achieve optimal results quickly, naive AI agents succeed but with prohibitive costs, and our proposed system bridges this gap through structured interfaces.

Our experiments reveal critical challenges for AI-driven scheduler optimization. The foremost concern is safety and reliability—how can we ensure that AI-generated code won't break the system through kernel crashes, soft-lockups, stalls, or starvation? How do we prevent negative impacts on target workloads while maintaining system stability? Equally pressing are efficiency and cost considerations: the current 33-minute generation time must be reduced to seconds for practical deployment, and the \$6 per-scheduler cost must be minimized to make workload-specific optimization economically viable. These fundamental challenges—balancing safety with performance, and capability with cost—motivate the design principles and system architecture we present next.