\section{Motivation}

\subsection{Key Motivations}

\subsubsection{Domain Knowledge Gap in Modern Infrastructure}

Modern computing infrastructure suffers from a fundamental disconnect between those who understand applications and those who manage systems. In cloud platforms, system administrators responsible for optimizing schedulers operate without deep insight into application behavior. A DevOps engineer configuring Kubernetes scheduler policies may have no knowledge of whether a particular workload is latency-sensitive or throughput-oriented, whether it exhibits phase behavior, or how its resource requirements evolve over time. This knowledge gap leads to conservative, suboptimal scheduling decisions that leave performance on the table.

The problem becomes even more acute for edge computing and personal devices, where the gap between user intent and system configuration is vast. Gaming enthusiasts desire optimal performance for their applications but lack the kernel programming knowledge to implement custom schedulers. Creative professionals using video editing software or 3D rendering applications need workload-specific optimizations but cannot modify kernel code. Edge device operators managing IoT deployments require scheduling policies tailored to their specific sensor data processing patterns but lack systems programming expertise. In serverless environments, the abstraction layers completely hide infrastructure details from developers, making it impossible to communicate scheduling requirements to the underlying system.

LLM agents offer a unique opportunity to bridge this gap. These agents can understand workload patterns and requirements from high-level descriptions, translating user intent into concrete scheduling policies. By democratizing access to expert-level optimization, AI agents make it possible for any user—from cloud operators to individual gamers—to achieve performance previously available only to those with deep kernel expertise.

\subsubsection{Technical Complexity of Scheduler Development}

The development of Linux kernel schedulers requires mastery of multiple complex domains that few developers possess. Kernel programming demands understanding of concurrency primitives, lock-free data structures, and the subtle interactions between different kernel subsystems. BPF development adds another layer of complexity with its verification requirements, limited instruction set, and restrictions on memory access patterns. Developers must also understand CPU architectures, cache hierarchies, NUMA topologies, and how scheduling decisions impact performance across these hardware features.

This steep learning curve creates a significant barrier to entry. Even experienced systems programmers often require months to become productive in kernel scheduler development. The consequence is that scheduler innovation proceeds slowly, limited by the small pool of qualified developers. Many optimization opportunities remain unexplored simply because the cost of implementation exceeds available resources. Organizations with unique workload patterns must either accept suboptimal performance or invest heavily in specialized kernel engineering talent.

\subsubsection{Dynamic Workload Adaptation}

Modern workloads exhibit complex phase behavior that changes faster than human operators can respond. Machine learning training workloads exemplify this challenge: they alternate between compute-intensive forward propagation phases, memory-bandwidth-limited weight updates, and communication-heavy gradient synchronization. Each phase benefits from different scheduling strategies—compute phases need CPU affinity and cache optimization, while communication phases benefit from co-scheduling of related tasks. Web applications experience traffic patterns that vary by orders of magnitude throughout the day, requiring different scheduling approaches for peak versus idle periods. Build systems present another challenge with their complex dependency graphs creating varying levels of parallelism as compilation progresses.

Manual scheduler reconfiguration cannot keep pace with these dynamic patterns. By the time a human operator detects a phase change and adjusts scheduling parameters, the workload may have already transitioned to a different phase. This reactive approach leads to persistent suboptimal performance. AI agents, in contrast, can continuously monitor workload behavior and adapt scheduling policies in real-time, potentially even predicting phase transitions based on historical patterns.

\subsection{Motivation Experiments}

To understand the challenges and opportunities of AI-driven scheduler generation, we tested state-of-the-art autonomous coding agents by giving Claude Code a simple prompt: "write a scheduler in eBPF" on a Linux 6.12 system with sched\_ext enabled. The AI agent successfully created a working FIFO scheduler without human help, but the process took 33 minutes, made 221 API calls, went through 15+ trial-and-error iterations with various compilation errors and BPF verifier rejections, initiated 8 web browsing sessions for documentation, consulted kernel source code 12 times, and cost approximately \$6 in API fees—compared to an experienced developer who completed the same task in 5 minutes at \$0.50 with only 1-2 iterations. The AI-generated code had serious quality issues: it used inefficient data structures like linked lists instead of arrays, performed unnecessary memory allocations in the scheduling hot path, showed poor CPU cache usage patterns, and missed obvious optimizations like per-CPU data structures to avoid lock contention. The cost and time made it impractical—\$6 per scheduler is too expensive for workload-specific optimization, 33 minutes is too slow for dynamic adaptation, and the multiple iterations waste computational resources. Safety concerns were also significant: the agent needed root access to load kernel modules, could potentially crash the system during testing, lacked built-in safety checks for performance regressions, and had no gradual rollout mechanisms so failures affected the entire system. These results show three clear approaches: human experts achieve optimal results quickly, naive AI agents succeed but with prohibitive costs, and our proposed system (as we will demonstrate) bridges this gap by combining AI capabilities with structured interfaces to address these fundamental challenges.

\subsection{Research Challenges}

Based on our experimental findings, we identify four critical research challenges that must be addressed to realize the vision of AI-driven scheduler optimization.

\subsubsection{Safety and Reliability}

Ensuring the safety of AI-generated kernel code represents perhaps the most critical challenge. We must guarantee that generated schedulers cannot crash the kernel through null pointer dereferences, infinite loops, or invalid memory accesses. The system must prevent soft-lockups where the scheduler consumes excessive CPU time, priority inversions where low-priority tasks block high-priority ones indefinitely, and starvation where some tasks never receive CPU time. Beyond preventing catastrophic failures, we must minimize negative impacts on production workloads, ensuring that even suboptimal scheduling decisions degrade performance gracefully rather than catastrophically. Finally, the system must provide robust rollback mechanisms that can quickly revert to known-good schedulers when problems are detected.

\subsubsection{Efficiency and Cost}

The current 33-minute generation time must be reduced to seconds for the approach to be practical in dynamic environments. This requires fundamental improvements in how AI agents approach scheduler generation, moving from trial-and-error to more directed synthesis. LLM API costs must be minimized while maintaining generation quality, requiring clever context management and caching strategies. The system must leverage experience from previous scheduler generation to avoid repeating work, building a knowledge base that grows over time. Costs must be amortized across multiple deployments, making workload-specific optimization economically viable for a broader range of users.

\subsubsection{Performance Optimization}

AI-generated code must match or exceed human expert performance to justify deployment. This requires ensuring that the AI understands performance implications of different implementation choices, from data structure selection to algorithm design. The system must automatically incorporate domain-specific optimizations that human experts would apply, such as cache-aware data layouts and lock-free algorithms where appropriate. Performance validation must occur before production deployment, with comprehensive benchmarking that captures both average-case and worst-case behavior. The system must support continuous improvement based on runtime feedback, learning from production performance to generate better schedulers over time.

\subsubsection{Generalization and Adaptability}

The framework must handle diverse workload types without requiring retraining or manual configuration for each new scenario. This demands architectures that can transfer knowledge between similar scheduling problems, recognizing patterns that apply across different but related workloads. As new hardware architectures emerge with different performance characteristics, the system must adapt automatically without requiring framework updates. User-specific requirements and constraints must be incorporated naturally, allowing customization without sacrificing the benefits of automated generation. The system must balance specialization for specific workloads with generalization across workload classes.

These challenges motivate our design principles and system architecture, which we present in the following section. By addressing each challenge systematically, we create a framework that makes AI-driven scheduler optimization both practical and beneficial.