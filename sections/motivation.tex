\section{Motivation}

\subsection{Key Motivations}

\subsubsection{Domain Knowledge Gap in Modern Infrastructure}

Modern computing infrastructure suffers from a fundamental disconnect between those who understand applications and those who manage systems. In cloud platforms, system administrators responsible for optimizing schedulers operate without deep insight into application behavior. A DevOps engineer configuring Kubernetes scheduler policies may have no knowledge of whether a particular workload is latency-sensitive or throughput-oriented, whether it exhibits phase behavior, or how its resource requirements evolve over time. This knowledge gap leads to conservative, suboptimal scheduling decisions that leave performance on the table.

The problem becomes even more acute for edge computing and personal devices, where the gap between user intent and system configuration is vast. Gaming enthusiasts desire optimal performance for their applications but lack the kernel programming knowledge to implement custom schedulers. Creative professionals using video editing software or 3D rendering applications need workload-specific optimizations but cannot modify kernel code. Edge device operators managing IoT deployments require scheduling policies tailored to their specific sensor data processing patterns but lack systems programming expertise. In serverless environments, the abstraction layers completely hide infrastructure details from developers, making it impossible to communicate scheduling requirements to the underlying system.

LLM agents offer a unique opportunity to bridge this gap. These agents can understand workload patterns and requirements from high-level descriptions, translating user intent into concrete scheduling policies. By democratizing access to expert-level optimization, AI agents make it possible for any user—from cloud operators to individual gamers—to achieve performance previously available only to those with deep kernel expertise.

\subsubsection{Technical Complexity of Scheduler Development}

The development of Linux kernel schedulers requires mastery of multiple complex domains that few developers possess. Kernel programming demands understanding of concurrency primitives, lock-free data structures, and the subtle interactions between different kernel subsystems. BPF development adds another layer of complexity with its verification requirements, limited instruction set, and restrictions on memory access patterns. Developers must also understand CPU architectures, cache hierarchies, NUMA topologies, and how scheduling decisions impact performance across these hardware features.

This steep learning curve creates a significant barrier to entry. Even experienced systems programmers often require months to become productive in kernel scheduler development. The consequence is that scheduler innovation proceeds slowly, limited by the small pool of qualified developers. Many optimization opportunities remain unexplored simply because the cost of implementation exceeds available resources. Organizations with unique workload patterns must either accept suboptimal performance or invest heavily in specialized kernel engineering talent.

\subsubsection{Dynamic Workload Adaptation}

Modern workloads exhibit complex phase behavior that changes faster than human operators can respond. Machine learning training workloads exemplify this challenge: they alternate between compute-intensive forward propagation phases, memory-bandwidth-limited weight updates, and communication-heavy gradient synchronization. Each phase benefits from different scheduling strategies—compute phases need CPU affinity and cache optimization, while communication phases benefit from co-scheduling of related tasks. Web applications experience traffic patterns that vary by orders of magnitude throughout the day, requiring different scheduling approaches for peak versus idle periods. Build systems present another challenge with their complex dependency graphs creating varying levels of parallelism as compilation progresses.

Manual scheduler reconfiguration cannot keep pace with these dynamic patterns. By the time a human operator detects a phase change and adjusts scheduling parameters, the workload may have already transitioned to a different phase. This reactive approach leads to persistent suboptimal performance. AI agents, in contrast, can continuously monitor workload behavior and adapt scheduling policies in real-time, potentially even predicting phase transitions based on historical patterns.

\subsection{Motivation Experiments}

To understand the challenges and opportunities of AI-driven scheduler generation, we conducted experiments using state-of-the-art autonomous coding agents. Our goal was to assess both the feasibility and current limitations of using AI to generate kernel schedulers without human intervention.

\subsubsection{Experiment Setup}

We designed our experiment to reflect a realistic scenario where a user without kernel programming expertise attempts to create a custom scheduler. We provided Claude Code, the most advanced autonomous coding agent available, with a simple prompt: "write a scheduler in eBPF." This minimal specification tests the agent's ability to understand the task, navigate the complex technical requirements, and produce working code. The experimental environment consisted of a Linux 6.12 system with sched\_ext enabled, providing the necessary infrastructure for BPF scheduler development. As a baseline for comparison, we measured the time required for an experienced kernel developer to implement the same basic FIFO scheduler.

\subsubsection{Results}

The AI agent successfully synthesized a functional FIFO scheduler without human intervention, demonstrating that autonomous scheduler generation is indeed feasible. However, the path to success revealed significant challenges that must be addressed for practical deployment.

The quantitative metrics paint a sobering picture of current limitations. The generation process required 33 minutes of wall-clock time, during which the agent made 221 separate API calls to the LLM. The agent underwent more than 15 trial-and-error iterations, encountering various compilation errors, BPF verifier rejections, and runtime failures before producing working code. Throughout this process, the agent initiated 8 web browsing sessions to search for eBPF documentation and consulted Linux kernel source code 12 times. The total cost for this single scheduler generation reached approximately \$6 in API fees.

In stark contrast, an experienced kernel developer completed the same task in just 5 minutes at an estimated cost of \$0.50 based on typical developer hourly rates. The developer required only 1-2 iterations, primarily for testing rather than error correction. This 6.6x time difference and 12x cost difference highlight the efficiency gap that must be closed for AI-driven scheduler generation to become practical.

\subsubsection{Key Observations}

Our analysis of the AI-generated scheduler revealed three critical categories of challenges that must be addressed by any practical framework.

First, code quality issues plague naive AI generation. The AI-generated scheduler exhibited higher overhead than necessary due to inefficient data structure choices, using linked lists where arrays would suffice and performing unnecessary memory allocations in the scheduling hot path. The code showed suboptimal CPU cache usage patterns, with data structures laid out in ways that increase cache misses. Most concerning, the AI missed several optimizations that would be obvious to human experts, such as avoiding lock contention through per-CPU data structures and minimizing scheduler decision complexity. These quality issues meant that despite being functionally correct, the AI-generated scheduler sometimes performed worse than the default CFS scheduler it was meant to improve.

Second, the cost and time requirements make the current approach prohibitive for production use. At \$6 per scheduler generation, organizations would face significant costs for workload-specific optimization. The 33-minute generation time is too slow for dynamic adaptation to changing workloads. The multiple iterations waste computational resources on both the client and server side, contributing to both cost and environmental concerns. These efficiency issues must be addressed through better frameworks and interfaces that guide the AI toward successful implementations more directly.

Third, safety and reliability concerns arise from the autonomous agent's broad system access requirements. The agent required root access to load kernel modules, creating security risks if the agent were compromised. During testing, the agent's generated code could potentially crash the system, requiring manual intervention to recover. The lack of built-in safety checks meant that performance regressions could go unnoticed until production deployment. The absence of gradual rollout mechanisms meant that failures affected the entire system rather than a controlled subset.

\subsection{Research Challenges}

Based on our experimental findings, we identify four critical research challenges that must be addressed to realize the vision of AI-driven scheduler optimization.

\subsubsection{Safety and Reliability}

Ensuring the safety of AI-generated kernel code represents perhaps the most critical challenge. We must guarantee that generated schedulers cannot crash the kernel through null pointer dereferences, infinite loops, or invalid memory accesses. The system must prevent soft-lockups where the scheduler consumes excessive CPU time, priority inversions where low-priority tasks block high-priority ones indefinitely, and starvation where some tasks never receive CPU time. Beyond preventing catastrophic failures, we must minimize negative impacts on production workloads, ensuring that even suboptimal scheduling decisions degrade performance gracefully rather than catastrophically. Finally, the system must provide robust rollback mechanisms that can quickly revert to known-good schedulers when problems are detected.

\subsubsection{Efficiency and Cost}

The current 33-minute generation time must be reduced to seconds for the approach to be practical in dynamic environments. This requires fundamental improvements in how AI agents approach scheduler generation, moving from trial-and-error to more directed synthesis. LLM API costs must be minimized while maintaining generation quality, requiring clever context management and caching strategies. The system must leverage experience from previous scheduler generation to avoid repeating work, building a knowledge base that grows over time. Costs must be amortized across multiple deployments, making workload-specific optimization economically viable for a broader range of users.

\subsubsection{Performance Optimization}

AI-generated code must match or exceed human expert performance to justify deployment. This requires ensuring that the AI understands performance implications of different implementation choices, from data structure selection to algorithm design. The system must automatically incorporate domain-specific optimizations that human experts would apply, such as cache-aware data layouts and lock-free algorithms where appropriate. Performance validation must occur before production deployment, with comprehensive benchmarking that captures both average-case and worst-case behavior. The system must support continuous improvement based on runtime feedback, learning from production performance to generate better schedulers over time.

\subsubsection{Generalization and Adaptability}

The framework must handle diverse workload types without requiring retraining or manual configuration for each new scenario. This demands architectures that can transfer knowledge between similar scheduling problems, recognizing patterns that apply across different but related workloads. As new hardware architectures emerge with different performance characteristics, the system must adapt automatically without requiring framework updates. User-specific requirements and constraints must be incorporated naturally, allowing customization without sacrificing the benefits of automated generation. The system must balance specialization for specific workloads with generalization across workload classes.

These challenges motivate our design principles and system architecture, which we present in the following section. By addressing each challenge systematically, we create a framework that makes AI-driven scheduler optimization both practical and beneficial.