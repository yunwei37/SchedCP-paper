\section{Motivation}
\label{sec:motivation}

\subsection{The Semantic Gap Problem}

\textbf{Domain Knowledge Gap in Modern Infrastructure}: In cloud platforms and serverless environments, DevOps engineers configuring Kubernetes policies often lack insight into whether workloads are latency-sensitive or throughput-oriented, leading to conservative scheduling that achieves less utilization in many datacenters. This gap is even more pronounced for edge and personal devices. Gamers seeking optimal performance, creative professionals needing workload-specific optimizations, and office workers managing documents all lack the kernel expertise to optimize their systems. LLM agents can bridge this semantic gap by understanding workload patterns extracted from source code and high-level descriptions like file metadata or deployment artifacts, and translating them into concrete scheduling policies, democratizing expert-level optimization for all users.

\textbf{Technical Complexity of Scheduler Development}: Designing Linux kernel schedulers requires mastering multiple complex domains: kernel programming with concurrency primitives and lock-free data structures, BPF verification with its limited instruction set and memory restrictions, and deep understanding of CPU architectures, cache hierarchies, and NUMA topologies. This steep learning curve means even experienced developers need months to become productive, limiting innovation to a small group of kernel experts. LLM agents with pre-trained domain knowledge can help bridge this expertise gap, enabling rapid scheduler development without years of specialized training.

\textbf{Dynamic Workload Adaptation}: Modern workloads exhibit complex phase behavior that changes faster than humans can respond. Machine learning training alternates between compute-intensive forward propagation and communication-heavy gradient synchronization; web applications see traffic varying by orders of magnitude daily; build systems show varying parallelism as dependencies resolve. Manual reconfiguration cannot keep pace. By the time humans detect and adjust for phase changes, workloads have already transitioned. AI agents can continuously monitor and adapt scheduling policies in real-time, responding in hours or minutes, 24 hours a day, 7 days a week. This is much faster and cost effective than human experts.

\subsection{Motivation Experiment}

To understand the practical challenges, we tested Claude Code with a simple prompt: "write a FIFO scheduler in eBPF", starts from an empty folder. We run it for 3 times, only one time is successful, one time the agent tried for 6 minutres, failed and try to give me a persude code, one timme the agent tried for 8 munites, and actually give me a working tracer for scheduler instead of scheduler itself. The successful generation required 33 minutes, 221 API calls, and 15+ trial-and-error iterations, costing approximately \$6, compared to an experienced eBPF developer typically completing the same task in 5 minutes. The generated code often exhibited poor quality and cause too much scheduling overhead, that actually worse than CFS. Safety concerns were paramount: the agent required root access, could crash the system during testing, and lacked gradual rollout mechanisms. These results highlight three approaches: human experts achieve optimal results quickly, naive AI agents succeed but with prohibitive costs, and our proposed system bridges this gap through structured interfaces.

\subsection{Challenges in applying LLM Agents to scheduler}

Our experiments reveal critical challenges for AI-driven scheduler optimization. \textbf{Performance improvement}: How can we make sure that the AI-generated scheduler can achieve better performance than the existing schedulers, not worse? \textbf{Safety and Reliability}: How can we ensure that AI-generated code won't break the system through kernel crashes, soft-lockups, stalls, or starvation? How do we prevent negative impacts on target workloads while maintaining system stability? \textbf{Efficiency and Cost}: Equally pressing are the current 33-minute generation time that must be reduced to seconds for practical deployment, and the \$6 per-scheduler cost that must be minimized to make workload-specific optimization economically viable. These fundamental challenges of balancing safety with performance, and capability with cost, motivate the design principles and system architecture we present next.