\section{Motivation}

\subsection{The Semantic Gap Problem}

\subsubsection{Domain Knowledge Gap in Modern Infrastructure}

Modern infrastructure has a fundamental disconnect between app experts and system managers, where cloud admins optimizing schedulers lack deep app behavior insight—a DevOps engineer configuring Kubernetes policies may not know if a workload is latency-sensitive or throughput-oriented, has phase behavior, or how resources evolve, causing conservative scheduling that achieves <50\% utilization in many HPC centers~\cite{feitelson2023utilization}. The problem is exacerbated by unprecedented workload diversity: one machine might run latency-critical web services needing microsecond responses, throughput-optimized batch jobs, ML workloads alternating between compute and communication phases with bursty CPU-accelerator coordination needs, serverless platforms with millisecond function execution, and microservices creating complex communication patterns affecting tail latency—each needing fundamentally different scheduling strategies that system managers lack visibility into. The gap worsens for edge computing and personal devices where gamers want optimal performance but lack kernel programming skills, creative professionals need workload-specific optimizations but can't modify kernels, Edge/IoT operators need scheduling for specific sensor patterns but lack systems expertise, and serverless abstraction layers hide infrastructure completely, preventing scheduling requirement communication. LLM agents can bridge this gap by understanding workload patterns from high-level descriptions and translating intent into concrete scheduling policies, democratizing expert-level optimization to let any user—cloud operators to gamers—achieve performance previously limited to kernel experts.

\subsubsection{Technical Complexity of Scheduler Development}

Linux scheduler development requires mastering multiple complex domains few developers have—kernel programming needs understanding of concurrency primitives, lock-free data structures, and subtle kernel subsystem interactions, while BPF adds complexity with verification requirements, limited instructions, and memory access restrictions, and developers must understand CPU architectures, cache hierarchies, NUMA topologies, and how scheduling impacts performance across hardware. This steep learning curve barriers entry as even experienced programmers need months for productive kernel scheduler development, causing scheduler innovation to be slow and limited by few qualified developers, leaving many optimizations unexplored because implementation costs exceed resources, forcing organizations with unique workloads to accept suboptimal performance or invest heavily in specialized kernel talent.

\subsubsection{Dynamic Workload Adaptation}

Modern workloads show complex phase behavior changing faster than humans can respond—ML training alternates between compute-intensive forward propagation, memory-limited weight updates, and communication-heavy gradient sync, with each phase needing different scheduling where compute needs CPU affinity and cache optimization while communication benefits from task co-scheduling, web apps have traffic varying by orders of magnitude daily needing different scheduling for peak vs idle, and build systems create challenges with dependency graphs causing varying parallelism during compilation. Manual reconfiguration can't keep pace with these dynamic patterns as when humans detect phase changes and adjust parameters, workloads may have already transitioned, causing this reactive approach to result in persistent suboptimal performance, whereas AI agents can continuously monitor workloads and adapt policies in real-time, potentially predicting phase transitions from historical patterns.

\subsection{Motivation Experiments}

To understand the challenges and opportunities of AI-driven scheduler generation, we tested state-of-the-art autonomous coding agents by giving Claude Code a simple prompt: "write a scheduler in eBPF" on a Linux 6.12 system with sched\_ext enabled. The AI agent successfully created a working FIFO scheduler without human help, but the process took 33 minutes, made 221 API calls, went through 15+ trial-and-error iterations with various compilation errors and BPF verifier rejections, initiated 8 web browsing sessions for documentation, consulted kernel source code 12 times, and cost approximately \$6 in API fees—compared to an experienced developer who completed the same task in 5 minutes at \$0.50 with only 1-2 iterations. The AI-generated code had serious quality issues: it used inefficient data structures like linked lists instead of arrays, performed unnecessary memory allocations in the scheduling hot path, showed poor CPU cache usage patterns, and missed obvious optimizations like per-CPU data structures to avoid lock contention. The cost and time made it impractical—\$6 per scheduler is too expensive for workload-specific optimization, 33 minutes is too slow for dynamic adaptation, and the multiple iterations waste computational resources. Safety concerns were also significant: the agent needed root access to load kernel modules, could potentially crash the system during testing, lacked built-in safety checks for performance regressions, and had no gradual rollout mechanisms so failures affected the entire system. These results show three clear approaches: human experts achieve optimal results quickly, naive AI agents succeed but with prohibitive costs, and our proposed system (as we will demonstrate) bridges this gap by combining AI capabilities with structured interfaces to address these fundamental challenges.

\subsection{Challenges}

Our experiments reveal critical challenges for AI-driven scheduler optimization. The foremost concern is safety and reliability—how can we ensure that AI-generated code won't break the system through kernel crashes, soft-lockups, stalls, or starvation? How do we prevent negative impacts on target workloads while maintaining system stability? Equally pressing are efficiency and cost considerations: the current 33-minute generation time must be reduced to seconds for practical deployment, and the \$6 per-scheduler cost must be minimized to make workload-specific optimization economically viable. These fundamental challenges—balancing safety with performance, and capability with cost—motivate the design principles and system architecture we present next.