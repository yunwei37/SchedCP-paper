\section{Conclusion and Future Work}

\subsection{Summary}

This paper presents the first comprehensive framework for using fully automatic LLM agents to dynamically optimize Linux schedulers, marking a fundamental shift in how operating systems can adapt to diverse and evolving workloads. Our work bridges the long-standing semantic gap between what applications need and what kernel schedulers provide, leveraging the unprecedented capabilities of modern AI agents to understand workload requirements and generate optimized scheduling algorithms automatically.

The technical contributions of our work span multiple dimensions. We developed a modular framework that can be leveraged by any AI agent, from open-source models to proprietary systems like Claude Code, ensuring broad accessibility and continuous improvement as AI capabilities advance. Our design principles—decoupling the "what to optimize" from "how to observe and act," maintaining context balance, providing composable tools, and enforcing safety-first design—establish a blueprint for AI-system interfaces that extends beyond schedulers to any system component. The self-evolving scheduler library represents a new paradigm where system software accumulates knowledge and improves over time, rather than remaining static between manual updates.

Our empirical results validate the transformative potential of this approach. Performance improvements ranging from 30-80\% across diverse workloads—from kernel compilation to latency-sensitive web services—demonstrate that significant optimization opportunities exist when schedulers can understand and adapt to specific workload patterns. The dramatic cost reductions of 85-88\% compared to naive AI approaches prove that with proper engineering, AI-driven optimization can be economically viable for widespread deployment. The framework's ability to operate across systems from edge devices to 256-core servers confirms its practical applicability to real-world infrastructure.

Beyond the immediate technical achievements, this work fundamentally democratizes system optimization. Expert-level performance, previously accessible only to organizations with specialized kernel engineering teams, can now be achieved by any user who can describe their workload requirements in natural language. Cloud operators can optimize for their specific service mix, game developers can tune for their particular graphics workloads, and researchers can experiment with novel scheduling strategies—all without writing a single line of kernel code. This democratization promises to unlock performance gains that have been theoretically possible but practically inaccessible due to the complexity of kernel development.

\subsection{Impact and Vision}

The implications of our work extend far beyond CPU scheduling to fundamentally reshape how we conceive, develop, and deploy system software. By demonstrating that AI agents can successfully generate kernel-level code that matches or exceeds human expert performance, we open possibilities that were previously confined to science fiction. The interfaces and principles we establish today will shape how AI interacts with systems software for years to come, making this work foundational for the future of operating systems.

We envision a future where every application runs on an operating system perfectly tuned for its specific needs. Instead of compromising with one-size-fits-all policies, each workload receives scheduling algorithms that understand its unique patterns and requirements. A video game could have a scheduler that prioritizes frame rendering threads while managing background asset loading, automatically adapting as players move between menu screens and intense action sequences. Scientific simulations could receive schedulers that understand their phase behavior, optimizing for compute intensity during calculation phases and communication efficiency during synchronization. This level of customization, impossible with traditional development approaches, becomes routine with AI-driven optimization.

The democratization of system optimization represents a paradigm shift in computing accessibility. Today, achieving optimal system performance requires rare expertise in kernel programming, performance analysis, and hardware architecture. Our framework makes this expertise available to anyone who can describe their requirements in natural language. Small businesses can achieve the same level of system optimization as tech giants, researchers can experiment with novel scheduling approaches without kernel expertise, and individual users can optimize their personal systems for their specific use cases. This democratization promises to unlock massive amounts of performance currently left on the table due to the expertise bottleneck.

Most profoundly, we enable operating systems that continuously evolve and improve without human intervention. Traditional OS development follows a punctuated equilibrium model—long periods of stasis interrupted by major releases that introduce new features and optimizations. Our self-evolving approach creates a system that learns from every workload it encounters, accumulating knowledge in its scheduler library and improving its optimization strategies. Performance gains compound over time as the system encounters more diverse workloads and discovers new optimization patterns. This continuous evolution means that systems get better at their jobs simply by doing them, a characteristic previously unique to human experts.

The principles we establish—decoupling AI and system responsibilities, balancing context and cost, providing composable tools, and maintaining safety-first design—generalize beyond schedulers to any domain where AI agents interact with complex systems. These principles could guide AI integration in databases, networks, distributed systems, and even domains outside computer science like robotics and autonomous vehicles. By solving the fundamental challenges of AI-system interaction in the context of kernel schedulers, we provide a template for the broader integration of AI into critical infrastructure.

\subsection{Future Work}

\subsubsection{Extended Scope}
While our current implementation focuses on CPU schedulers as a proof of concept, the framework's architecture naturally extends to other operating system policies that could benefit from workload-specific optimization. Each extension presents unique challenges and opportunities that future research should explore.

Memory management represents the most immediate extension opportunity. Modern systems struggle with one-size-fits-all page replacement algorithms that cannot adapt to application-specific access patterns. AI agents could analyze memory access traces to generate custom page replacement policies that understand whether an application exhibits sequential, random, or working-set behaviors. NUMA (Non-Uniform Memory Access) policies present another rich optimization space where AI could generate policies that understand application communication patterns and data sharing relationships. The challenge lies in the tight timing constraints of memory management decisions and the need for even more stringent safety guarantees than CPU scheduling.

I/O scheduling offers compelling optimization opportunities as storage devices become increasingly sophisticated. NVMe SSDs with multiple queues, persistent memory, and computational storage devices create a complex optimization space that traditional I/O schedulers cannot fully exploit. AI agents could generate I/O schedulers that understand application access patterns, coordinate with CPU scheduling for better cache efficiency, and exploit device-specific features. Network queue management in high-speed networks presents similar opportunities, where AI could generate policies that understand application communication patterns and Quality of Service requirements. The key challenge is handling the extreme performance requirements of modern I/O devices where scheduling decisions must be made in microseconds.

Power management has become critical as energy costs rise and environmental concerns grow. Current DVFS (Dynamic Voltage and Frequency Scaling) policies use simple heuristics that miss opportunities for power savings while maintaining performance. AI agents could generate policies that understand application phase behavior, predicting when reduced performance is acceptable and when full power is needed. Core parking strategies, thermal management, and heterogeneous core scheduling (big.LITTLE architectures) all present optimization opportunities where understanding workload characteristics can yield significant energy savings. The challenge is balancing multiple objectives—performance, power, and thermal constraints—while maintaining system responsiveness.

\subsubsection{Cross-Component Optimization}
The most exciting future direction involves coordinated optimization across multiple system components, moving beyond optimizing individual policies to considering system-wide interactions. Modern applications stress multiple resources simultaneously, and optimal performance requires coordinated decisions across CPU, memory, I/O, and power management.

Joint CPU-memory scheduling for memory-intensive workloads represents a prime example. Applications like in-memory databases and scientific simulations are often limited by memory bandwidth rather than CPU cycles. AI agents could generate coordinated policies that schedule threads based on their memory access patterns, ensuring that threads with complementary access patterns run simultaneously to maximize bandwidth utilization. This requires understanding both computation patterns and memory access behaviors, synthesizing policies that optimize across both dimensions.

System-wide policy synthesis considering all resources simultaneously represents the ultimate goal. An AI agent could analyze an application holistically, understanding its CPU, memory, I/O, and power requirements, then generate a complete set of policies optimized for that specific workload. This might involve trading CPU performance for memory bandwidth, adjusting I/O priorities based on computation phases, or coordinating power management with task scheduling. The challenge is managing the exponentially larger design space and ensuring that policies remain comprehensible and debuggable.

\subsubsection{Industry Adoption Path}
Transitioning from research prototype to widespread industry adoption requires addressing technical, organizational, and trust challenges. We envision a carefully orchestrated adoption path that builds confidence through incremental deployment and proven results.

Partnership with major cloud providers represents the most promising initial deployment avenue. Cloud environments offer ideal conditions for AI-driven optimization: diverse workloads, sophisticated monitoring infrastructure, and technical teams capable of evaluating and deploying experimental systems. We plan to work with cloud providers to deploy our framework in limited production environments, starting with non-critical workloads and gradually expanding as confidence grows. These deployments will generate valuable data on real-world performance, identify edge cases not covered in our evaluation, and demonstrate economic value at scale. Cloud providers' ability to A/B test at massive scale will provide definitive evidence of our framework's benefits.

Developing certification processes for AI-generated schedulers addresses the trust and compliance requirements of enterprise deployments. We propose establishing a certification authority that validates AI-generated schedulers through comprehensive testing, formal analysis where possible, and performance benchmarking. Certified schedulers would carry guarantees about safety properties, performance characteristics, and behavior under edge conditions. This certification process would evolve from simple functional testing to sophisticated analysis including adversarial testing, formal verification of critical properties, and long-term stability validation. Industry participation in defining certification standards ensures they meet real-world requirements while maintaining academic rigor.

Creating industry standards for AI-system interfaces ensures interoperability and prevents fragmentation as multiple AI agents and system frameworks emerge. Standards should cover API specifications for AI agents to interact with system components, safety requirements and verification procedures, performance metrics and evaluation methodologies, and semantic specifications for workload descriptions. By establishing standards early, we can ensure that innovations in AI agents immediately benefit all compliant systems, while system improvements are accessible to all AI agents. This standardization effort requires collaboration between academia, industry, and standards bodies to balance innovation with stability.

\subsubsection{Enhanced AI Capabilities}
The rapid evolution of AI capabilities presents opportunities to dramatically improve our framework's effectiveness. Each advancement in AI technology can be immediately leveraged through our modular architecture.

Multi-modal understanding represents a paradigm shift in how AI agents can comprehend system behavior. Future agents could simultaneously analyze code structure, performance graphs, system logs, and even architectural diagrams to build comprehensive understanding of optimization opportunities. A multi-modal agent could correlate visual patterns in performance graphs with code structures, identifying optimization opportunities that would be invisible when analyzing each modality separately. This richer understanding enables more sophisticated optimizations and better debugging of performance issues.

Longer context windows, already expanding rapidly, will enable AI agents to consider entire codebases and complete performance histories when making optimization decisions. With million-token context windows on the horizon, agents could analyze months of performance data, understand complex interactions between different system components, and generate optimizations that consider long-term patterns rather than just immediate behavior. This expanded context transforms the optimization problem from local improvements to global system optimization.

Faster inference times open possibilities for real-time optimization in response to changing workload conditions. As inference speeds improve from seconds to milliseconds, AI agents could continuously monitor system behavior and adjust scheduling policies in real-time. This enables adaptive systems that respond immediately to phase changes, load spikes, or new application deployments. The framework could even generate specialized schedulers on-demand as new applications start, ensuring optimal performance from the first execution.

\subsubsection{Theoretical Foundations}
While our empirical results demonstrate the framework's effectiveness, important theoretical questions remain that could further improve and validate our approach.

Formal verification of AI-generated schedulers represents the gold standard for safety assurance. While the eBPF verifier provides basic safety guarantees, formal verification could prove higher-level properties like fairness, liveness, and real-time guarantees. The challenge lies in automatically generating verification conditions from AI-generated code and developing verification techniques that scale to complex schedulers. Success in this area would enable deployment in safety-critical systems where current testing-based approaches are insufficient.

Understanding the theoretical bounds on performance improvements achievable through AI-driven optimization would help set realistic expectations and identify when optimization efforts have reached diminishing returns. These bounds likely depend on workload characteristics, hardware constraints, and the fundamental limits of scheduling theory. Theoretical analysis could identify workload classes where significant improvements are possible versus those where current schedulers are near-optimal, guiding deployment efforts to where they provide maximum value.

Convergence guarantees for the self-evolution process would ensure that the system improves monotonically rather than oscillating between different solutions. Questions include whether the scheduler library converges to a stable set of high-performing schedulers, how quickly convergence occurs for different workload classes, and what conditions might cause divergence or performance regression. Understanding these dynamics helps design better learning algorithms and provides confidence in long-term system behavior.

\subsection{Challenges and Considerations}

\subsubsection{Trust and Reliability}
The deployment of AI-generated code in kernel space represents a fundamental shift in how we think about system software reliability. Building trust requires not just technical solutions but also organizational and cultural changes in how we develop, validate, and deploy critical system components.

Extensive testing and gradual rollout procedures form the foundation of trust building. Our framework implements multiple layers of testing, from unit tests of individual scheduler functions to system-wide stress tests under adverse conditions. However, testing can never be exhaustive, particularly for AI-generated code that might explore unusual implementation strategies. We advocate for canary deployments where new schedulers run on progressively larger fractions of infrastructure, with automatic rollback capabilities if anomalies are detected. This gradual approach allows organizations to build confidence through experience while limiting potential impact.

Clear audit trails and explainable decisions address the "black box" concern often raised about AI systems. Every scheduler generation includes detailed logs of the AI's reasoning process, design decisions, and implementation choices. The framework generates human-readable documentation explaining why specific algorithms were chosen and how they are expected to improve performance. When performance regressions occur, the audit trail enables rapid root cause analysis. This transparency is essential for building trust among system administrators who must ultimately take responsibility for system behavior.

Industry collaboration on standards and best practices accelerates trust building through shared experience and collective validation. We propose establishing working groups that bring together cloud providers, enterprise users, OS vendors, and researchers to share deployment experiences, develop best practices, and create certification standards. This collaborative approach ensures that trust is built on broad empirical evidence rather than isolated experiments.

\subsubsection{Ethical Considerations}
The power to automatically optimize system behavior raises important ethical questions that the community must address proactively.

Fairness in resource allocation becomes more complex when AI systems make scheduling decisions. Traditional schedulers implement simple fairness policies that treat all tasks equally or according to configured priorities. AI-generated schedulers might discover that certain optimizations benefit some workloads at the expense of others, raising questions about how to balance competing interests. We must develop frameworks for specifying fairness constraints that AI agents respect, ensuring that optimization doesn't lead to discrimination or resource starvation for certain users or applications.

Privacy implications arise from the detailed workload analysis required for optimization. To generate effective schedulers, AI agents must understand application behavior patterns, which might reveal sensitive information about what applications are doing. Medical imaging workloads have distinct patterns from financial modeling, potentially allowing inference about the nature of computation. We must develop privacy-preserving optimization techniques that can improve performance without exposing sensitive workload characteristics.

Environmental impact of optimization decisions presents both opportunities and challenges. AI-driven optimization could significantly reduce energy consumption by better matching resources to workload needs. However, the framework itself consumes resources for AI inference and continuous optimization. We must carefully balance the energy saved through better scheduling against the energy consumed by the optimization process itself. Furthermore, optimization goals must explicitly consider environmental impact, not just performance, leading to schedulers that balance speed with sustainability.

\subsubsection{Technical Debt}
As our framework matures and the scheduler library grows, we must proactively address accumulating technical debt to ensure long-term sustainability.

Maintenance of AI-generated code presents unique challenges different from human-written code. When a bug is discovered in a traditional scheduler, developers can understand the original author's intent and fix the issue. With AI-generated code, the "intent" is embedded in the AI's training and generation process, making fixes more challenging. We propose maintaining not just the generated code but also the context, prompts, and performance data that led to its creation. This enables regeneration with fixes rather than manual patching, maintaining the AI-driven optimization approach even during maintenance.

Evolution of the framework with changing AI capabilities requires careful architectural planning. As AI models improve, they will generate better code with fewer safety issues and more sophisticated optimizations. Our framework must evolve to leverage these capabilities while maintaining compatibility with previously generated schedulers. This suggests a versioned approach where each scheduler is tagged with the AI model version that created it, enabling appropriate validation and migration strategies as models improve.

Documentation and understanding of generated policies becomes crucial as the scheduler library grows. While AI can generate functional code, ensuring that humans can understand, debug, and learn from this code requires additional effort. We propose automatic generation of multiple documentation levels: high-level algorithm descriptions for system administrators, detailed implementation notes for developers, and formal specifications where possible for verification tools. This comprehensive documentation ensures that AI-generated optimizations contribute to human knowledge rather than creating an incomprehensible black box.

\subsection{Call to Action}

This work opens new possibilities for adaptive, application-aware operating systems that can automatically optimize themselves for changing workloads. The transformation we envision requires collective effort from the entire systems community—researchers, practitioners, and industry leaders must collaborate to realize the full potential of AI-driven system optimization.

We call on the community to contribute to the open-source implementation, available at our project repository. The framework is designed for extensibility, with clear interfaces for adding new AI agents, optimization algorithms, and safety mechanisms. Whether you're a systems researcher exploring novel scheduling algorithms, an AI researcher improving code generation, or a practitioner with real-world workloads to optimize, your contributions will advance the state of the art. The modular architecture ensures that improvements in any component benefit the entire system.

Sharing workload traces and performance data accelerates progress for everyone. The effectiveness of AI-driven optimization depends on understanding diverse workload patterns. We've established a repository for anonymized workload traces where organizations can contribute data from their production systems. This shared resource enables researchers to evaluate new approaches on realistic workloads and helps AI agents learn from a broader range of scenarios than any single organization could provide. Contributing data not only advances research but also ensures that future optimizations work well for your specific workload patterns.

Developing new safety mechanisms and verification tools addresses one of the most critical challenges in AI-generated kernel code. We need innovations in static analysis that can understand AI-generated code patterns, dynamic verification that can catch subtle performance regressions, formal methods that scale to complex schedulers, and debugging tools that help humans understand AI-generated optimizations. The safety challenge is too important for any single group to solve alone—we need the collective expertise of the formal methods, systems, and AI communities.

Exploring applications to other system components multiplies the impact of this work. While we focused on CPU scheduling, the principles and infrastructure we've developed apply broadly. We encourage researchers to explore AI-driven optimization for memory management, file systems, network stacks, distributed systems, and even hardware design. Each new domain brings unique challenges but also opportunities for dramatic performance improvements. The framework we've established provides a template that can accelerate progress in these areas.

This work has implications beyond schedulers. As AI agents become more powerful, the interfaces we design today will shape how AI interacts with systems software tomorrow. Our framework demonstrates that with proper design, AI can democratize system optimization—making expert-level performance accessible to users from cloud operators to gamers, while paving the way for truly self-optimizing operating systems.

Helping establish standards for AI-system interfaces ensures that innovations remain composable and interoperable. As AI agents proliferate and system components become AI-aware, we need standards that enable different components to work together seamlessly. This includes API specifications, safety requirements, performance metrics, and semantic descriptions of system behavior. Early standardization efforts will prevent fragmentation and ensure that the benefits of AI-driven optimization are broadly accessible.

The era of static, one-size-fits-all operating systems is ending. For fifty years, we've built systems that treat all workloads the same, missing enormous optimization opportunities. With AI agents as partners, we can build systems that understand application needs, adapt to changing conditions, and optimize continuously. This is not just an incremental improvement—it's a fundamental shift in how we think about system software. Instead of systems that require expert knowledge to optimize, we're creating systems that optimize themselves. Instead of performance improvements that require years of development, we're enabling optimizations that happen automatically as workloads evolve.

The future of operating systems is not just self-driving, but self-evolving. Systems that learn from experience, accumulate knowledge, and improve continuously without human intervention. This work takes the first crucial steps on that journey, demonstrating that AI-driven OS optimization is not just possible but practical. The path ahead is challenging but filled with opportunity. Together, we can build the intelligent, adaptive systems that will power the next generation of computing. The revolution in operating systems has begun—join us in shaping its future.