\section{Related Work}

Our work stands at the intersection of multiple rapidly evolving research areas: reinforcement learning for system optimization, AI applications in operating systems, the emerging capabilities of large language models for code generation, and the revolutionary potential of autonomous AI agents. We position our contributions relative to these fields, highlighting both how we build upon existing work and where we make fundamental advances.

\subsection{RL-based Scheduler Optimization}

The application of reinforcement learning to scheduling problems has emerged as one of the most promising directions in systems research, with several landmark papers demonstrating the potential for learned policies to outperform traditional heuristics. However, these approaches face fundamental limitations that motivate our LLM-based approach.

\textbf{Decima}~\cite{mao2019decima}, presented at SIGCOMM 2019, represents a watershed moment in applying deep learning to systems problems. The system uses graph neural networks to learn job scheduling policies for datacenter environments, reasoning about complex dependencies between tasks in distributed computing jobs. By representing jobs as directed acyclic graphs and using a novel neural architecture that can process variable-sized inputs, Decima achieves remarkable results—reducing average job completion time by up to 40\% compared to traditional heuristics. However, Decima's approach requires extensive training for each specific workload type, often needing millions of scheduling decisions before converging to good policies. More critically, it operates purely on statistical patterns in job structures without understanding what the jobs actually do or why certain scheduling decisions might be beneficial. This limitation becomes apparent when workloads exhibit rare but important patterns that weren't well-represented in training data.

\textbf{Firm}~\cite{qiu2020firm}, published at OSDI 2020, extends the RL paradigm to address multi-resource cluster scheduling while maintaining fairness constraints—a notoriously difficult problem in distributed systems. The system models resource allocation as a multi-agent reinforcement learning problem, where each job acts as an agent competing for cluster resources. Firm's innovation lies in its ability to learn policies that balance efficiency with fairness, preventing scenarios where some jobs are starved while others monopolize resources. The system achieves impressive results in production deployments, improving cluster utilization by 25-30\% while maintaining strict fairness guarantees. However, like Decima, Firm cannot reason about application semantics or understand why certain workloads might benefit from specific scheduling strategies. The learned policies remain black boxes that provide no explanation for their decisions, making debugging and trust difficult in production environments.

\textbf{Recent advances} in RL-based scheduling have pushed the boundaries further. Multi-objective RL schedulers like MrSch~\cite{zhang2024mrsch} simultaneously optimize for multiple resources including CPU, memory, and network bandwidth, achieving up to 48\% performance improvements in heterogeneous clusters. These systems use sophisticated neural architectures including attention mechanisms and transformer models to capture complex interactions between different resource types. Other work has explored hierarchical RL for multi-level scheduling decisions and meta-learning approaches that can quickly adapt to new workload types. While these advances demonstrate the continued potential of RL for scheduling, they also highlight a fundamental limitation: the inability to leverage domain knowledge or understand application intent.

\textbf{Key distinction}: The fundamental difference between our approach and pure RL methods lies in semantic understanding. While RL-based schedulers must learn everything from scratch through trial and error, our LLM-based system can immediately apply knowledge from its training on vast amounts of code and documentation. When faced with a compilation workload, for instance, an RL system sees only task durations and dependencies, while our system understands that it's looking at a build process and can apply known optimizations like prioritizing tasks on the critical path. We combine the best of both worlds—using LLMs for initial understanding and generation, then applying RL for workload-specific optimization.

\subsection{AI for Systems}

The broader application of artificial intelligence to systems problems has evolved from simple parameter tuning to fundamental reimagining of core system components. This progression provides important context for understanding how our work represents the next logical step in this evolution.

\textbf{Learned Indexes} represent one of the most radical applications of machine learning to systems, as demonstrated by Kraska et al.~\cite{kraska2018learned} in their influential SIGMOD 2018 paper. The key insight is that database indexes are fundamentally models that map keys to positions, and neural networks can learn these mappings more efficiently than traditional B-trees for certain data distributions. By replacing B-trees with small neural networks, learned indexes achieve up to 70\% memory savings and 3x lookup performance improvements. This work sparked a renaissance in rethinking fundamental system components through the lens of machine learning. Subsequent research has extended learned indexes to handle updates, developed hybrid approaches that combine traditional and learned structures, and applied similar ideas to other data structures like bloom filters and hash tables. The success of learned indexes demonstrates that AI can improve even the most fundamental and well-studied system components.

\textbf{Query Optimization} represents another successful application domain where AI techniques have shown significant promise. Neo~\cite{marcus2019neo}, presented at VLDB 2019, uses deep reinforcement learning to optimize database query execution plans. Traditional query optimizers rely on cost models that are notoriously inaccurate, leading to suboptimal plan choices. Neo learns from actual query execution times to build more accurate cost models and make better optimization decisions. The system achieves up to 2x performance improvements on complex analytical queries. More recent work has explored using transformer models to understand query structure and predict optimal join orders, and applying multi-armed bandits to adaptively choose between different query execution strategies. These successes in query optimization demonstrate AI's ability to improve complex decision-making in systems where traditional heuristics fall short.

\textbf{Configuration Tuning} has emerged as a practical application area where AI provides immediate value. OtterTune~\cite{vanaken2017ottertune}, developed at CMU, uses Gaussian Process regression and collaborative filtering to automatically tune database configuration parameters. The system addresses a critical pain point—modern databases have hundreds of configuration knobs, and even expert DBAs struggle to find optimal settings. OtterTune learns from previous tuning sessions across different workloads to recommend configurations for new deployments, achieving performance within 94\% of expert DBAs with minimal training data. Similar approaches have been applied to web server configuration, container resource allocation, and distributed system parameters. While these tools demonstrate AI's practical value, they remain limited to optimizing existing parameters rather than creating new algorithms or implementations.

\textbf{Our contribution} represents a fundamental leap beyond these existing applications. While learned indexes replace specific data structures and configuration tuners optimize parameters, we use AI to generate entire system components—complete schedulers with new algorithms tailored to specific workloads. This moves from AI as an optimization tool to AI as a system designer. Our approach also differs in leveraging large language models' semantic understanding rather than purely statistical learning. When OtterTune sees a configuration parameter, it treats it as an opaque number to optimize. When our system sees a scheduler parameter, it understands its semantic meaning and how it affects system behavior. This semantic understanding enables more intelligent and explainable optimizations.

\subsection{LLMs in Systems and Code Generation}

The emergence of large language models with sophisticated code understanding and generation capabilities has opened unprecedented opportunities for automated system optimization. These models, trained on vast corpora of code and documentation, possess knowledge that spans from high-level algorithms to low-level implementation details, making them uniquely suited for systems tasks that traditionally required years of human expertise.

\textbf{Code Generation} capabilities have advanced dramatically with systems like Codex~\cite{chen2021codex} (powering GitHub Copilot), GPT-4, and Claude demonstrating remarkable ability to generate complex systems code. GitHub Copilot has transformed software development by providing context-aware code suggestions that often match or exceed human-written code quality. Studies show that developers using Copilot complete tasks 55\% faster on average, with the tool being particularly effective for boilerplate code and common patterns. However, these tools are designed as developer assistants rather than autonomous agents. They excel at completing code snippets and implementing well-defined functions but cannot independently design and implement entire system components. More importantly, they lack the feedback loop necessary for optimization—they generate code based on patterns in training data but cannot observe runtime behavior and iterate accordingly. Recent advances have pushed capabilities further, with models generating entire applications from specifications, but the focus remains on functional correctness rather than performance optimization.

\textbf{Systems Understanding} represents another crucial capability where LLMs have shown surprising competence. Recent work by Wang et al.~\cite{wang2024llmsys} demonstrates that LLMs can analyze and explain complex system behaviors, debugging performance issues and suggesting optimizations. Their evaluation shows that GPT-4 can correctly diagnose 78\% of performance problems in distributed systems when provided with logs and metrics. LLMs have also proven capable of understanding kernel code, with studies showing they can explain Linux kernel functions with accuracy comparable to experienced developers. This understanding extends to performance implications—models can predict which code changes are likely to improve or degrade performance based on patterns learned from millions of code examples. However, existing applications have focused on analysis and explanation rather than synthesis. While an LLM can explain why a scheduler might be inefficient, prior to our work there were no systems that could automatically generate improved implementations.

\textbf{Mapper Generation} by Wei et al.~\cite{wei2024mapper} represents the closest prior work to our approach. Their system uses LLMs to generate mappers that optimize parallel program execution on heterogeneous hardware. By representing the mapping problem as a domain-specific language (DSL) generation task, they enable LLMs to produce code that assigns computation to different processing units (CPUs, GPUs, accelerators) based on workload characteristics. The system achieves impressive 3.8× speedups on average across various parallel workloads. The key insight is that LLMs can understand both the high-level structure of parallel algorithms and the low-level details of hardware capabilities, bridging the semantic gap that makes manual optimization difficult. However, mapper generation operates in a more constrained domain than kernel scheduler generation. Mappers work with well-defined parallel patterns and clear performance models, while schedulers must handle arbitrary workloads with complex, emergent behaviors. Our work extends this approach to the significantly more challenging domain of kernel schedulers, where safety requirements are stricter, performance implications more subtle, and the interaction with system state more complex.

\subsection{sched\_ext and eBPF Schedulers}

The introduction of sched\_ext represents a paradigm shift in Linux kernel development, enabling safe, dynamic scheduler implementation for the first time in the kernel's history. This framework provides the essential foundation that makes our AI-driven approach possible, offering both the flexibility needed for experimentation and the safety guarantees required for production deployment.

\textbf{The sched\_ext Framework} fundamentally changes how schedulers can be developed and deployed. Traditional Linux scheduler development required modifying kernel source code, recompiling the entire kernel, and rebooting systems—a process that could take hours and risk system stability. With sched\_ext, schedulers are implemented as BPF programs that can be loaded and unloaded dynamically without system restart. The framework provides comprehensive hooks into the scheduling subsystem, allowing BPF programs to control task enqueueing, CPU selection, load balancing, and idle CPU management. This flexibility enables implementation of novel scheduling algorithms that would be impractical with traditional kernel development. Performance overhead is minimal—typically less than 1\% for production workloads—making sched\_ext suitable for performance-critical environments. The framework has already gained significant adoption, with major technology companies deploying custom schedulers in production to optimize for their specific workloads.

\textbf{Production Schedulers} developed for sched\_ext demonstrate the framework's capability to support sophisticated scheduling policies. scx\_rusty implements a work-stealing scheduler with advanced load balancing, achieving better performance than CFS for many parallel workloads. The scheduler uses per-CPU queues with periodic work stealing to balance load, implementing NUMA-aware stealing policies that minimize cross-socket traffic. scx\_layered provides hierarchical scheduling with cgroup awareness, allowing different scheduling policies for different application classes. This scheduler has proven particularly valuable in cloud environments where multiple tenants require isolation and different performance guarantees. scx\_central implements a centralized scheduling approach optimized for NUMA systems, where a single scheduling queue can actually improve performance by making better global decisions. These production schedulers validate that eBPF is capable of implementing complex scheduling algorithms with performance matching or exceeding traditional kernel schedulers.

\textbf{Safety Guarantees} provided by the eBPF verifier address one of the most critical challenges in dynamic scheduler generation. The verifier performs exhaustive static analysis of BPF programs before loading, ensuring they cannot crash the kernel, access invalid memory, or enter infinite loops. This verification includes checking that all memory accesses are bounds-checked, all loops have provable termination conditions, and all kernel helper functions are called with valid arguments. The verifier's conservative approach means that some correct programs may be rejected, but it guarantees that accepted programs are safe. This safety mechanism is crucial for our AI-driven approach—without it, automatically generated scheduler code could pose unacceptable risks to system stability. The verifier acts as a safety net that allows us to experiment with AI-generated code while maintaining production-level reliability.

\textbf{Our innovation} builds upon sched\_ext's foundation to add intelligence to the scheduling layer. While sched\_ext provides the mechanism for safe, dynamic scheduler implementation, it still requires human experts to design and implement scheduling algorithms. Our contribution is automating this process—using AI to understand workload requirements, generate appropriate scheduling algorithms, and implement them as eBPF programs. This combination of sched\_ext's flexibility and safety with AI's pattern recognition and code generation capabilities enables a new paradigm where schedulers can be automatically optimized for specific workloads. We are the first to demonstrate that AI agents can successfully generate production-quality kernel schedulers, opening new possibilities for adaptive system optimization.

\subsection{AI Agents and Autonomous Systems}

The years 2024-2025 mark an inflection point in AI capabilities, with the emergence of truly autonomous agents capable of complex software engineering tasks. These agents represent a qualitative leap from previous AI systems, combining multiple capabilities into cohesive systems that can work independently on challenging technical problems.

\textbf{Claude Code}, along with similar autonomous agents like GitHub Copilot Workspace and Devin, demonstrates unprecedented software development capabilities. These agents go far beyond simple code completion to engage in complete software engineering workflows. Claude Code can understand complex requirements expressed in natural language, architect solutions, implement code across multiple files, write tests, debug failures, and iterate based on results—all without human intervention. In benchmarks, these agents successfully complete real-world programming tasks that previously required hours of human developer time. The key innovation is the integration of multiple AI capabilities: natural language understanding for requirements, code generation for implementation, program analysis for debugging, and planning algorithms for managing complex multi-step tasks. Our motivation experiments with Claude Code revealed both its potential and current limitations for systems programming, informing our framework design to maximize strengths while mitigating weaknesses.

\textbf{AIOS}~\cite{mei2024aios} represents complementary research that proposes fundamental OS changes to support AI agents as first-class citizens. Their vision includes LLM-aware process scheduling that understands the unique requirements of AI workloads, such as large memory footprints and bursty computation patterns. The system provides new abstractions for AI agents including semantic memory spaces, natural language system calls, and AI-specific resource management. While our work focuses on using AI agents to optimize traditional OS components, AIOS explores how operating systems themselves must evolve to support AI workloads. The two approaches are synergistic—our AI-optimized schedulers could run within an AIOS environment, while AIOS could use our techniques to automatically optimize its own scheduling policies. This convergence points toward a future where AI and operating systems are deeply integrated at multiple levels.

\textbf{Agent Capabilities} have expanded dramatically to encompass the full software development lifecycle. Modern agents combine multiple specialized models and tools: code generation models trained on vast repositories, testing frameworks that automatically generate test cases, debugging tools that can trace execution and identify bugs, and planning systems that break complex tasks into manageable steps. These agents can now handle tasks requiring deep understanding of system constraints, performance implications, and correctness requirements. They can read and understand existing codebases, identify optimization opportunities, and implement improvements while maintaining compatibility. The agents' ability to iterate based on feedback is particularly crucial—they can run tests, observe failures, and modify their approach accordingly. This closed-loop capability is essential for our scheduler optimization use case, where performance can only be validated through actual execution. By leveraging these comprehensive agent capabilities, we can automate scheduler development tasks that previously required expert kernel developers.

\subsection{Positioning Our Work}

Our work is unique in several ways:

\begin{enumerate}
\item \textbf{First to use LLM agents for OS scheduler generation}: While others use ML for scheduling decisions, we generate entire schedulers.

\item \textbf{Semantic Understanding}: Unlike pure RL approaches, our system understands workload intent and requirements.

\item \textbf{Production-Ready}: Built on sched\_ext, our generated schedulers can run in production Linux systems.

\item \textbf{Self-Evolving}: Our scheduler library grows through experience, unlike static ML models.

\item \textbf{Safety-First Design}: We address the unique challenges of AI-generated kernel code through comprehensive safety mechanisms.
\end{enumerate}

\subsection{Limitations of Existing Approaches}

A critical analysis of existing approaches reveals fundamental limitations that motivate our research direction. Each category of current solutions faces inherent constraints that prevent them from achieving the vision of truly adaptive, intelligent system optimization.

\textbf{RL-based methods}, despite their successes, face several fundamental limitations that become apparent in production deployments. The most significant is the extensive training requirement—Decima requires millions of scheduling decisions before converging to good policies, making it impractical for workloads that change frequently or new deployment scenarios. This training is not transferable; a policy learned for one workload type provides little benefit for another, necessitating retraining from scratch. The inability to leverage domain knowledge means that RL systems must rediscover well-known scheduling principles through trial and error, wasting computational resources and time. The policies produced are typically neural networks that provide no explanation for their decisions, making debugging nearly impossible when things go wrong. Most critically, RL methods miss semantic optimization opportunities—they cannot understand that a workload represents compilation and apply known optimizations for build systems. They see only statistical patterns in task durations and miss the higher-level structure that could inform better scheduling decisions.

\textbf{Traditional auto-tuning} approaches, while practical and widely deployed, operate within narrow constraints that limit their effectiveness. These systems can only optimize existing parameters rather than create new algorithms or implementation strategies. OtterTune might find the optimal buffer pool size for a database, but it cannot invent a new buffer management algorithm better suited to the workload. The requirement for manual feature engineering means that optimization is limited to dimensions that humans have already identified and exposed as tunable parameters. Many optimization opportunities exist in implementation choices that are not exposed as parameters. Adaptation to new workloads is slow because these systems must observe sufficient samples to build accurate models, and they cannot leverage understanding of workload semantics to accelerate this process. The fundamental limitation is that auto-tuning operates within the design space defined by human developers rather than exploring new possibilities.

\textbf{Static schedulers}, including the default Linux CFS, embody a one-size-fits-all philosophy that becomes increasingly problematic as workload diversity grows. These schedulers cannot adapt to workload-specific requirements without manual intervention, missing significant optimization opportunities. When new workload patterns emerge—such as the rise of microservices or machine learning training—schedulers require manual updates that may take years to develop and deploy. The pace of innovation is fundamentally limited by developer resources; even when optimization opportunities are known, implementing them requires scarce kernel development expertise. Static schedulers must make conservative choices that work reasonably well for all workloads rather than optimizing aggressively for specific patterns. This leads to a lowest-common-denominator approach that leaves significant performance on the table for specialized workloads.

Our LLM agent-based approach addresses these limitations through a fundamentally different architecture. By combining semantic understanding from LLMs, code generation capabilities, and continuous learning through RL, we create a system that can understand workload intent, generate specialized implementations, and improve through experience. This unified framework breaks through the constraints that limit existing approaches, enabling a new generation of adaptive, intelligent system optimization.