\section{Related Work}
\label{sec:related}

While RL-based scheduling approaches like Decima~\cite{mao2019decima}, Firm~\cite{qiu2020firm}, and MrSch~\cite{zhang2024mrsch} achieve up to 48\% performance improvements, they require millions of training decisions and miss semantic optimization opportunities. LLMs in systems show promise—Wang et al.~\cite{wang2024llmsys} demonstrate GPT-4 diagnosing 78\% of distributed system problems, and mapper generation~\cite{wei2024mapper} achieves 3.8× speedups for parallel programs, though in constrained domains. Our work uniquely combines semantic understanding with production readiness: unlike RL approaches learning from scratch or auto-tuners like OtterTune~\cite{vanaken2017ottertune} optimizing parameters, we leverage LLMs' pre-trained knowledge to generate entirely new scheduling algorithms through an autonomous optimization loop. Built on sched\_ext with eBPF safety guarantees, our self-evolving scheduler library accumulates knowledge across workloads, representing the first AI agents generating production-quality kernel schedulers from natural language requirements.