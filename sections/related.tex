\section{Related Work}
\label{sec:related}

Machine learning has a history of optimizing systems, including learned indexes~\cite{kraska2018learned}, database tuning~\cite{marcus2019neo,vanaken2017ottertune}, and RL-based job schedulers~\cite{mao2019decima,qiu2020firm,zhang2024mrsch} supported by platforms like Park~\cite{mao2019park}. However, these methods require extensive training, lack the semantic understanding to transfer knowledge across diverse workloads, or need human specify high level optimization goals. While recent work has applied LLMs to system diagnostics~\cite{wang2024llmsys} and  code generation~\cite{wei2024mapper,10.1145/3672197.3673434}, our work is the first to use an autonomous agent to design, configure and generate kernel schedulers, and apply them for end-to-end system optimization without human involvement. By leveraging LLM Agent reasoning, tool usage with sched\_ext and eBPF, our framework uniquely bridges the semantic gap between application needs and system policy.

% Machine learning has transformed fundamental system components. Learned indexes~\cite{kraska2018learned} replace B-trees with neural networks, achieving up to 70\% memory savings and 3x lookup performance improvements. In scheduling specifically, Decima~\cite{mao2019decima} uses graph neural networks for datacenter job scheduling, reducing completion time by 40\%, while Firm~\cite{qiu2020firm} addresses multi-resource cluster scheduling with fairness constraints, improving utilization by 25-30\%. MrSch~\cite{zhang2024mrsch} extends these approaches achieving up to 48\% performance improvements. Park~\cite{mao2019park} provides a general platform for applying RL to systems problems. Beyond scheduling, Neo~\cite{marcus2019neo} applies deep RL to database query optimization, achieving 2x performance improvements, while OtterTune~\cite{vanaken2017ottertune} uses Gaussian Process regression to tune database configurations, reaching 94\% of expert DBA performance. However, these approaches share fundamental limitations: they require extensive training (millions of decisions), cannot transfer knowledge between workloads, and operate on statistical patterns without semantic understanding. Recent work demonstrates LLMs' potential in systems optimization. Wang et al.~\cite{wang2024llmsys} show GPT-4 diagnosing 78\% of distributed system problems, and mapper generation~\cite{wei2024mapper} achieves 3.8Ã— speedups for parallel programs, though in constrained domains. Our work uniquely combines semantic understanding with production readiness: unlike RL approaches learning from scratch or auto-tuners optimizing parameters, we leverage LLMs' pre-trained knowledge to generate entirely new scheduling algorithms through an autonomous optimization loop. Built on sched\_ext with eBPF safety guarantees, our self-evolving scheduler library accumulates knowledge across workloads, representing the first AI agents generating production-quality kernel schedulers from natural language requirements.